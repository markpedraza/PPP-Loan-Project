{"cells":[{"cell_type":"code","execution_count":1,"id":"e70cc25b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting handyspark\n","  Downloading handyspark-0.2.2a1-py2.py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: pyspark in /usr/lib/spark/python (from handyspark) (3.5.1)\n","Requirement already satisfied: matplotlib in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (3.8.4)\n","Requirement already satisfied: numpy in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (1.26.4)\n","Requirement already satisfied: scipy in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (1.11.4)\n","Requirement already satisfied: seaborn in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (0.13.2)\n","Requirement already satisfied: pandas in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (2.1.4)\n","Requirement already satisfied: scikit-learn in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (1.3.2)\n","Collecting findspark (from handyspark)\n","  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n","Requirement already satisfied: pyarrow in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (14.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (23.1)\n","Requirement already satisfied: pillow>=8 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (2.9.0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->handyspark) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->handyspark) (2024.2)\n","Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pyspark->handyspark) (0.10.9.7)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from scikit-learn->handyspark) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from scikit-learn->handyspark) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->handyspark) (1.16.0)\n","Downloading handyspark-0.2.2a1-py2.py3-none-any.whl (39 kB)\n","Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n","Installing collected packages: findspark, handyspark\n","Successfully installed findspark-2.0.1 handyspark-0.2.2a1\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0mRequirement already satisfied: gcsfs in /opt/conda/miniconda3/lib/python3.11/site-packages (2023.12.2.post1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (3.10.10)\n","Requirement already satisfied: decorator>4.1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (5.1.1)\n","Requirement already satisfied: fsspec==2023.12.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2023.12.2)\n","Requirement already satisfied: google-auth>=1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2.35.0)\n","Requirement already satisfied: google-auth-oauthlib in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (1.1.0)\n","Requirement already satisfied: google-cloud-storage in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2.13.0)\n","Requirement already satisfied: requests in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2.31.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.16.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.21.0)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.4.1)\n","Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.7.2)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (1.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (2024.8.30)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.65.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (4.24.4)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.25.0)\n","Requirement already satisfied: cffi>=1.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-crc32c<2.0dev,>=1.0->google-cloud-storage->gcsfs) (1.16.0)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n","Requirement already satisfied: propcache>=0.2.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.2.0)\n","Requirement already satisfied: pycparser in /opt/conda/miniconda3/lib/python3.11/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-cloud-storage->gcsfs) (2.21)\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0mCollecting openpyxl\n","  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n","Collecting et-xmlfile (from openpyxl)\n","  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n","Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n","\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m250.9/250.9 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n","\u001B[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n","Installing collected packages: et-xmlfile, openpyxl\n","Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install handyspark\n","!pip install gcsfs\n","!pip install openpyxl"]},{"cell_type":"code","execution_count":2,"id":"1a570d4f","metadata":{"scrolled":true},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-20241127e-m.us-central1-b.c.cis4400-group-project-ppp.internal:35107\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fd39cbf0190>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":2,"id":"c469342a","metadata":{},"outputs":[],"source":["import numpy as np\n","import gcsfs\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","np.bool = np.bool_"]},{"cell_type":"code","execution_count":4,"id":"c3dde7fb","metadata":{},"outputs":[],"source":["from handyspark import *"]},{"cell_type":"markdown","id":"f5d92799","metadata":{},"source":["# Cleaning PPP data"]},{"cell_type":"code","execution_count":5,"id":"7cc50f50","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#Get data from the csv's that were downloaded\n","ppp_df = spark.read.csv(\"gs://ppp-loans-bucket/landing/ppp_loans*\", header=True, inferSchema=True)"]},{"cell_type":"code","execution_count":6,"id":"b7085198","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- LoanNumber: long (nullable = true)\n"," |-- DateApproved: string (nullable = true)\n"," |-- SBAOfficeCode: integer (nullable = true)\n"," |-- ProcessingMethod: string (nullable = true)\n"," |-- BorrowerName: string (nullable = true)\n"," |-- BorrowerAddress: string (nullable = true)\n"," |-- BorrowerCity: string (nullable = true)\n"," |-- BorrowerState: string (nullable = true)\n"," |-- BorrowerZip: string (nullable = true)\n"," |-- LoanStatusDate: string (nullable = true)\n"," |-- LoanStatus: string (nullable = true)\n"," |-- Term: string (nullable = true)\n"," |-- SBAGuarantyPercentage: string (nullable = true)\n"," |-- InitialApprovalAmount: string (nullable = true)\n"," |-- CurrentApprovalAmount: string (nullable = true)\n"," |-- UndisbursedAmount: string (nullable = true)\n"," |-- FranchiseName: string (nullable = true)\n"," |-- ServicingLenderLocationID: string (nullable = true)\n"," |-- ServicingLenderName: string (nullable = true)\n"," |-- ServicingLenderAddress: string (nullable = true)\n"," |-- ServicingLenderCity: string (nullable = true)\n"," |-- ServicingLenderState: string (nullable = true)\n"," |-- ServicingLenderZip: string (nullable = true)\n"," |-- RuralUrbanIndicator: string (nullable = true)\n"," |-- HubzoneIndicator: string (nullable = true)\n"," |-- LMIIndicator: string (nullable = true)\n"," |-- BusinessAgeDescription: string (nullable = true)\n"," |-- ProjectCity: string (nullable = true)\n"," |-- ProjectCountyName: string (nullable = true)\n"," |-- ProjectState: string (nullable = true)\n"," |-- ProjectZip: string (nullable = true)\n"," |-- CD: string (nullable = true)\n"," |-- JobsReported: string (nullable = true)\n"," |-- NAICSCode: string (nullable = true)\n"," |-- Race: string (nullable = true)\n"," |-- Ethnicity: string (nullable = true)\n"," |-- UTILITIES_PROCEED: string (nullable = true)\n"," |-- PAYROLL_PROCEED: string (nullable = true)\n"," |-- MORTGAGE_INTEREST_PROCEED: double (nullable = true)\n"," |-- RENT_PROCEED: double (nullable = true)\n"," |-- REFINANCE_EIDL_PROCEED: string (nullable = true)\n"," |-- HEALTH_CARE_PROCEED: double (nullable = true)\n"," |-- DEBT_INTEREST_PROCEED: double (nullable = true)\n"," |-- BusinessType: string (nullable = true)\n"," |-- OriginatingLenderLocationID: string (nullable = true)\n"," |-- OriginatingLender: string (nullable = true)\n"," |-- OriginatingLenderCity: string (nullable = true)\n"," |-- OriginatingLenderState: string (nullable = true)\n"," |-- Gender: string (nullable = true)\n"," |-- Veteran: string (nullable = true)\n"," |-- NonProfit: string (nullable = true)\n"," |-- ForgivenessAmount: string (nullable = true)\n"," |-- ForgivenessDate: string (nullable = true)\n","\n"]}],"source":["ppp_df.printSchema()"]},{"cell_type":"code","execution_count":7,"id":"390288ea","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 3:=======================================================> (39 + 1) / 40]\r"]},{"name":"stdout","output_type":"stream","text":["This dataset contains 11468210 records.\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["num_records = ppp_df.count()\n","print(\"This dataset contains {} records.\".format(num_records))"]},{"cell_type":"code","execution_count":8,"id":"8cd38561","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/lib/spark/python/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n","  warnings.warn(\n","/usr/lib/spark/python/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n","  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n","24/11/27 21:23:31 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","                                                                                \r"]},{"data":{"text/plain":["LoanNumber                            0\n","DateApproved                          0\n","SBAOfficeCode                        28\n","ProcessingMethod                      0\n","BorrowerName                          0\n","BorrowerAddress                      32\n","BorrowerCity                         28\n","BorrowerState                       165\n","BorrowerZip                         197\n","LoanStatusDate                   169089\n","LoanStatus                            0\n","Term                                  0\n","SBAGuarantyPercentage                 0\n","InitialApprovalAmount                 0\n","CurrentApprovalAmount                 0\n","UndisbursedAmount                  1143\n","FranchiseName                  11318087\n","ServicingLenderLocationID            61\n","ServicingLenderName                  31\n","ServicingLenderAddress               28\n","ServicingLenderCity                  28\n","ServicingLenderState                 29\n","ServicingLenderZip                   28\n","RuralUrbanIndicator                   0\n","HubzoneIndicator                      0\n","LMIIndicator                          4\n","BusinessAgeDescription                2\n","ProjectCity                          28\n","ProjectCountyName                   631\n","ProjectState                         29\n","ProjectZip                           29\n","CD                                  527\n","JobsReported                          8\n","NAICSCode                        132321\n","Race                                  2\n","Ethnicity                             0\n","UTILITIES_PROCEED               7879865\n","PAYROLL_PROCEED                   12120\n","MORTGAGE_INTEREST_PROCEED      11191324\n","RENT_PROCEED                   10948739\n","REFINANCE_EIDL_PROCEED         11347006\n","HEALTH_CARE_PROCEED            11260730\n","DEBT_INTEREST_PROCEED          11332472\n","BusinessType                       2291\n","OriginatingLenderLocationID          32\n","OriginatingLender                    29\n","OriginatingLenderCity                29\n","OriginatingLenderState               29\n","Gender                                1\n","Veteran                               1\n","NonProfit                      11214042\n","ForgivenessAmount                897732\n","ForgivenessDate                  897702\n","Name: missing, dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["#Count nulls in each row, so we can eventually drop them\n","hsdf = HandyFrame(ppp_df)\n","hsdf.isnull()"]},{"cell_type":"code","execution_count":9,"id":"12d94ec8","metadata":{},"outputs":[],"source":["#Drop nulls, and columns with mostly nulls.\n","#The exception to dropping is NonProfit and FranchiseName. These are to be used in dimensions later despite their nulls.\n","to_drop_columns = [\"MORTGAGE_INTEREST_PROCEED\",\"RENT_PROCEED\",\"REFINANCE_EIDL_PROCEED\",\n","               \"HEALTH_CARE_PROCEED\",\"DEBT_INTEREST_PROCEED\",\"UTILITIES_PROCEED\"]\n","ignore_columns = [\"NonProfit\",\"FranchiseName\"]"]},{"cell_type":"code","execution_count":18,"id":"cbbcd240","metadata":{},"outputs":[],"source":["#function takes in a spark dataframe, then drops nulls in ALL rows. Accepts a list of columns to skip in this process\n","#This function is meant for dfs with a large amount of columns with small amount of nulls in each column.\n","#\n","#BEFORE USING THIS FUNCTION, DROP COLUMNS THAT HAVE A HIGH PERCENTAGE OF NULLS\n","#OTHERWISE THE WHOLE DF WILL PRACTICALLY BE DROPPED.\n","\n","def drop_nulls_in_rows(df, list_of_columns_to_ignore=None):\n","    #get a extremely small sample just so we can find the rows we are dealing with using pandas\n","    sample_sdf = df.limit(1)\n","    pandas_df = sample_sdf.toPandas()\n"," \n","    #Now we get our list of columns that we will drop nulls in\n","    columns = pandas_df.columns\n","    \n","    #If any value of the list_of_columns_to_ignore is in the columns, we take that column out.\n","    if list_of_columns_to_ignore is not None:\n","        # Filter out the columns that are to be ignored\n","        columns = [col for col in pandas_df.columns if col not in list_of_columns_to_ignore]\n","    \n","    \n","    #With the columns extracted, loop through every column and filter it so we dont get nulls.\n","    for column in columns:\n","        print(\"Removing nulls in \"+column+\"...\")\n","        df = df.filter(column+\" is not NULL\")\n","    \n","    return df"]},{"cell_type":"code","execution_count":11,"id":"4c5aea3f","metadata":{},"outputs":[],"source":["#function that drops a list of columns in a pyspark df\n","def drop_columns(df, list_of_columns):\n","    for column in list_of_columns:\n","        print(\"Removing column \"+column+\"...\")\n","        df = df.drop(column)\n","    \n","    return df"]},{"cell_type":"code","execution_count":12,"id":"44e34378","metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Removing column MORTGAGE_INTEREST_PROCEED...\n","Removing column RENT_PROCEED...\n","Removing column REFINANCE_EIDL_PROCEED...\n","Removing column HEALTH_CARE_PROCEED...\n","Removing column DEBT_INTEREST_PROCEED...\n","Removing column UTILITIES_PROCEED...\n"]}],"source":["#Dropping columns\n","ppp_df = drop_columns(ppp_df,to_drop_columns)"]},{"cell_type":"code","execution_count":19,"id":"1c559f72","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Removing nulls in LoanNumber...\n","Removing nulls in DateApproved...\n","Removing nulls in SBAOfficeCode...\n","Removing nulls in ProcessingMethod...\n","Removing nulls in BorrowerName...\n","Removing nulls in BorrowerAddress...\n","Removing nulls in BorrowerCity...\n","Removing nulls in BorrowerState...\n","Removing nulls in BorrowerZip...\n","Removing nulls in LoanStatusDate...\n","Removing nulls in LoanStatus...\n","Removing nulls in Term...\n","Removing nulls in SBAGuarantyPercentage...\n","Removing nulls in InitialApprovalAmount...\n","Removing nulls in CurrentApprovalAmount...\n","Removing nulls in UndisbursedAmount...\n","Removing nulls in ServicingLenderLocationID...\n","Removing nulls in ServicingLenderName...\n","Removing nulls in ServicingLenderAddress...\n","Removing nulls in ServicingLenderCity...\n","Removing nulls in ServicingLenderState...\n","Removing nulls in ServicingLenderZip...\n","Removing nulls in RuralUrbanIndicator...\n","Removing nulls in HubzoneIndicator...\n","Removing nulls in LMIIndicator...\n","Removing nulls in BusinessAgeDescription...\n","Removing nulls in ProjectCity...\n","Removing nulls in ProjectCountyName...\n","Removing nulls in ProjectState...\n","Removing nulls in ProjectZip...\n","Removing nulls in CD...\n","Removing nulls in JobsReported...\n","Removing nulls in NAICSCode...\n","Removing nulls in Race...\n","Removing nulls in Ethnicity...\n","Removing nulls in PAYROLL_PROCEED...\n","Removing nulls in BusinessType...\n","Removing nulls in OriginatingLenderLocationID...\n","Removing nulls in OriginatingLender...\n","Removing nulls in OriginatingLenderCity...\n","Removing nulls in OriginatingLenderState...\n","Removing nulls in Gender...\n","Removing nulls in Veteran...\n","Removing nulls in ForgivenessAmount...\n","Removing nulls in ForgivenessDate...\n"]}],"source":["#Dropping all rows with a null, bar a few from the list that was created earlier\n","ppp_df = drop_nulls_in_rows(ppp_df,ignore_columns)"]},{"cell_type":"code","execution_count":20,"id":"9e42d060","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+----------------+\n","|ForgivenessDate|forgiveness_date|\n","+---------------+----------------+\n","|     06/11/2021|      2021-06-11|\n","|     07/13/2021|      2021-07-13|\n","|     09/13/2022|      2022-09-13|\n","|     05/18/2021|      2021-05-18|\n","|     07/07/2021|      2021-07-07|\n","|     06/10/2021|      2021-06-10|\n","|     07/22/2021|      2021-07-22|\n","|     07/28/2021|      2021-07-28|\n","|     11/09/2021|      2021-11-09|\n","|     06/11/2021|      2021-06-11|\n","|     06/14/2021|      2021-06-14|\n","|     06/22/2021|      2021-06-22|\n","|     01/12/2022|      2022-01-12|\n","|     07/27/2021|      2021-07-27|\n","|     01/17/2023|      2023-01-17|\n","|     06/28/2021|      2021-06-28|\n","|     06/11/2021|      2021-06-11|\n","|     06/11/2021|      2021-06-11|\n","|     06/11/2021|      2021-06-11|\n","|     06/11/2021|      2021-06-11|\n","+---------------+----------------+\n","only showing top 20 rows\n","\n","+------------+-------------+\n","|DateApproved|date_approved|\n","+------------+-------------+\n","|  08/08/2020|   2020-08-08|\n","|  04/14/2020|   2020-04-14|\n","|  04/17/2021|   2021-04-17|\n","|  04/14/2020|   2020-04-14|\n","|  04/11/2020|   2020-04-11|\n","|  06/10/2020|   2020-06-10|\n","|  04/11/2020|   2020-04-11|\n","|  04/06/2020|   2020-04-06|\n","|  04/29/2020|   2020-04-29|\n","|  04/15/2020|   2020-04-15|\n","|  04/28/2020|   2020-04-28|\n","|  04/14/2020|   2020-04-14|\n","|  04/11/2020|   2020-04-11|\n","|  04/11/2020|   2020-04-11|\n","|  05/23/2021|   2021-05-23|\n","|  04/08/2020|   2020-04-08|\n","|  04/04/2020|   2020-04-04|\n","|  04/07/2020|   2020-04-07|\n","|  04/10/2020|   2020-04-10|\n","|  04/04/2020|   2020-04-04|\n","+------------+-------------+\n","only showing top 20 rows\n","\n","+--------------+----------------+\n","|LoanStatusDate|loan_status_date|\n","+--------------+----------------+\n","|    07/22/2021|      2021-07-22|\n","|    08/21/2021|      2021-08-21|\n","|    10/06/2022|      2022-10-06|\n","|    06/09/2021|      2021-06-09|\n","|    08/13/2021|      2021-08-13|\n","|    07/14/2021|      2021-07-14|\n","|    08/20/2021|      2021-08-20|\n","|    08/20/2021|      2021-08-20|\n","|    11/23/2021|      2021-11-23|\n","|    07/08/2021|      2021-07-08|\n","|    07/08/2021|      2021-07-08|\n","|    07/20/2021|      2021-07-20|\n","|    04/07/2022|      2022-04-07|\n","|    08/19/2021|      2021-08-19|\n","|    02/16/2023|      2023-02-16|\n","|    07/21/2021|      2021-07-21|\n","|    07/20/2021|      2021-07-20|\n","|    07/21/2021|      2021-07-21|\n","|    07/20/2021|      2021-07-20|\n","|    07/20/2021|      2021-07-20|\n","+--------------+----------------+\n","only showing top 20 rows\n","\n"]},{"data":{"text/plain":["DataFrame[LoanNumber: bigint, DateApproved: string, SBAOfficeCode: int, ProcessingMethod: string, BorrowerName: string, BorrowerAddress: string, BorrowerCity: string, BorrowerState: string, BorrowerZip: string, LoanStatus: string, Term: string, SBAGuarantyPercentage: string, InitialApprovalAmount: string, CurrentApprovalAmount: string, UndisbursedAmount: string, FranchiseName: string, ServicingLenderLocationID: string, ServicingLenderName: string, ServicingLenderAddress: string, ServicingLenderCity: string, ServicingLenderState: string, ServicingLenderZip: string, RuralUrbanIndicator: string, HubzoneIndicator: string, LMIIndicator: string, BusinessAgeDescription: string, ProjectCity: string, ProjectCountyName: string, ProjectState: string, ProjectZip: string, CD: string, JobsReported: string, NAICSCode: string, Race: string, Ethnicity: string, PAYROLL_PROCEED: string, BusinessType: string, OriginatingLenderLocationID: string, OriginatingLender: string, OriginatingLenderCity: string, OriginatingLenderState: string, Gender: string, Veteran: string, NonProfit: string, ForgivenessAmount: string, ForgivenessDate: string, forgiveness_date: date, date_approved: date, loan_status_date: date]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["#Turn date columns into datatime datatypes.\n","#Date Columns to transform: (\"ForgivenessDate\",\"DateApproved\",\"LoanStatusDate\")\n","from pyspark.sql.functions import to_date\n","\n","# Convert the date columns of type string to type datetime\n","ppp_df = ppp_df.withColumn(\"forgiveness_date\", to_date(ppp_df[\"ForgivenessDate\"], \"MM/dd/yyyy\"))\n","ppp_df.select(\"ForgivenessDate\",\"forgiveness_date\").show()\n","ppp_df = ppp_df.drop(\"ForgivenessDate\")\n","\n","ppp_df = ppp_df.withColumn(\"date_approved\", to_date(ppp_df[\"DateApproved\"], \"MM/dd/yyyy\"))\n","ppp_df.select(\"DateApproved\",\"date_approved\").show()\n","ppp_df = ppp_df.drop(\"DateApproved\")\n","\n","ppp_df = ppp_df.withColumn(\"loan_status_date\", to_date(ppp_df[\"LoanStatusDate\"], \"MM/dd/yyyy\"))\n","ppp_df.select(\"LoanStatusDate\",\"loan_status_date\").show()\n","ppp_df = ppp_df.drop(\"LoanStatusDate\")"]},{"cell_type":"code","execution_count":21,"id":"50c19903","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/lib/spark/python/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n","  warnings.warn(\n","/usr/lib/spark/python/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n","  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n","                                                                                \r"]},{"data":{"text/plain":["LoanNumber                            0\n","DateApproved                          0\n","SBAOfficeCode                         0\n","ProcessingMethod                      0\n","BorrowerName                          0\n","BorrowerAddress                       0\n","BorrowerCity                          0\n","BorrowerState                         0\n","BorrowerZip                           0\n","LoanStatusDate                        0\n","LoanStatus                            0\n","Term                                  0\n","SBAGuarantyPercentage                 0\n","InitialApprovalAmount                 0\n","CurrentApprovalAmount                 0\n","UndisbursedAmount                     0\n","FranchiseName                  10258886\n","ServicingLenderLocationID             0\n","ServicingLenderName                   0\n","ServicingLenderAddress                0\n","ServicingLenderCity                   0\n","ServicingLenderState                  0\n","ServicingLenderZip                    0\n","RuralUrbanIndicator                   0\n","HubzoneIndicator                      0\n","LMIIndicator                          0\n","BusinessAgeDescription                0\n","ProjectCity                           0\n","ProjectCountyName                     0\n","ProjectState                          0\n","ProjectZip                            0\n","CD                                    0\n","JobsReported                          0\n","NAICSCode                             0\n","Race                                  0\n","Ethnicity                             0\n","PAYROLL_PROCEED                       0\n","BusinessType                          0\n","OriginatingLenderLocationID           0\n","OriginatingLender                     0\n","OriginatingLenderCity                 0\n","OriginatingLenderState                0\n","Gender                                0\n","Veteran                               0\n","NonProfit                      10159024\n","ForgivenessAmount                     0\n","ForgivenessDate                       0\n","forgiveness_date                      0\n","date_approved                         0\n","loan_status_date                      0\n","Name: missing, dtype: int64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["#Count nulls again to see if all nulls are dropped. Theoretically, there should be no nulls.\n","hsdf = HandyFrame(ppp_df)\n","hsdf.isnull()"]},{"cell_type":"code","execution_count":22,"id":"fca8bd53","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 19:==================================================>     (36 + 4) / 40]\r"]},{"name":"stdout","output_type":"stream","text":["Dropped 1062142 records. New count is 10406068\n","Roughly 0.91% of rows were dropped.\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["#Count records to see how many records are dropped compared to before\n","new_num_records = ppp_df.count()\n","difference = num_records - new_num_records\n","print(\"Dropped \"+str(difference)+\" records. New count is \"+str(new_num_records))\n","print(\"Roughly \"+str(round(new_num_records/num_records,2))+\"% of rows were dropped.\")"]},{"cell_type":"code","execution_count":23,"id":"394a9560","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#With our cleaned data, we write it back to the cleaned folder\n","ppp_df.write.parquet(\"gs://ppp-loans-bucket/cleaned\",mode=\"overwrite\")"]},{"cell_type":"markdown","id":"e19f9b48","metadata":{},"source":["# Cleaning GPD data"]},{"cell_type":"code","execution_count":24,"id":"166f9214","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>GeoFIPS</th>\n","      <th>GeoName</th>\n","      <th>Region</th>\n","      <th>TableName</th>\n","      <th>LineCode</th>\n","      <th>IndustryClassification</th>\n","      <th>Description</th>\n","      <th>Unit</th>\n","      <th>2017</th>\n","      <th>2018</th>\n","      <th>2019</th>\n","      <th>2020</th>\n","      <th>2021</th>\n","      <th>2022</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>United States</td>\n","      <td>NaN</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>19612102000</td>\n","      <td>20193896000</td>\n","      <td>20692087000</td>\n","      <td>20234074000</td>\n","      <td>21407692000</td>\n","      <td>21822037000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>United States</td>\n","      <td>NaN</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>102.967</td>\n","      <td>105.507</td>\n","      <td>103.171</td>\n","      <td>109.156</td>\n","      <td>111.268</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>United States</td>\n","      <td>NaN</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>19612102000</td>\n","      <td>20656516000</td>\n","      <td>21521395000</td>\n","      <td>21322950000</td>\n","      <td>23594031000</td>\n","      <td>25744108000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>216615470</td>\n","      <td>220808767</td>\n","      <td>224944577</td>\n","      <td>222081439</td>\n","      <td>231892626</td>\n","      <td>235807320</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>101.936</td>\n","      <td>103.845</td>\n","      <td>102.523</td>\n","      <td>107.053</td>\n","      <td>108.86</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9529</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>104.559</td>\n","      <td>109.552</td>\n","      <td>109.329</td>\n","      <td>116.661</td>\n","      <td>119.324</td>\n","    </tr>\n","    <tr>\n","      <th>9530</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>681310123</td>\n","      <td>730567674</td>\n","      <td>776281078</td>\n","      <td>781272363</td>\n","      <td>880142487</td>\n","      <td>974682556</td>\n","    </tr>\n","    <tr>\n","      <th>9531</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>3797440495</td>\n","      <td>3956948041</td>\n","      <td>4108525822</td>\n","      <td>4048649569</td>\n","      <td>4342903004</td>\n","      <td>4385657757</td>\n","    </tr>\n","    <tr>\n","      <th>9532</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>104.2</td>\n","      <td>108.192</td>\n","      <td>106.615</td>\n","      <td>114.364</td>\n","      <td>115.49</td>\n","    </tr>\n","    <tr>\n","      <th>9533</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>3797440495</td>\n","      <td>4026578971</td>\n","      <td>4252235190</td>\n","      <td>4254017130</td>\n","      <td>4732878464</td>\n","      <td>5066773749</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9534 rows × 14 columns</p>\n","</div>"],"text/plain":["      GeoFIPS         GeoName  Region TableName  LineCode  \\\n","0           0   United States     NaN    CAGDP1         1   \n","1           0   United States     NaN    CAGDP1         2   \n","2           0   United States     NaN    CAGDP1         3   \n","3        1000         Alabama     5.0    CAGDP1         1   \n","4        1000         Alabama     5.0    CAGDP1         2   \n","...       ...             ...     ...       ...       ...   \n","9529    97000  Rocky Mountain     7.0    CAGDP1         2   \n","9530    97000  Rocky Mountain     7.0    CAGDP1         3   \n","9531    98000        Far West     8.0    CAGDP1         1   \n","9532    98000        Far West     8.0    CAGDP1         2   \n","9533    98000        Far West     8.0    CAGDP1         3   \n","\n","     IndustryClassification  \\\n","0                       ...   \n","1                       ...   \n","2                       ...   \n","3                       ...   \n","4                       ...   \n","...                     ...   \n","9529                    ...   \n","9530                    ...   \n","9531                    ...   \n","9532                    ...   \n","9533                    ...   \n","\n","                                            Description  \\\n","0         Real GDP (thousands of chained 2017 dollars)    \n","1             Chain-type quantity indexes for real GDP    \n","2     Current-dollar GDP (thousands of current dolla...   \n","3         Real GDP (thousands of chained 2017 dollars)    \n","4             Chain-type quantity indexes for real GDP    \n","...                                                 ...   \n","9529          Chain-type quantity indexes for real GDP    \n","9530  Current-dollar GDP (thousands of current dolla...   \n","9531      Real GDP (thousands of chained 2017 dollars)    \n","9532          Chain-type quantity indexes for real GDP    \n","9533  Current-dollar GDP (thousands of current dolla...   \n","\n","                                   Unit         2017         2018  \\\n","0     Thousands of chained 2017 dollars  19612102000  20193896000   \n","1                        Quantity index          100      102.967   \n","2                  Thousands of dollars  19612102000  20656516000   \n","3     Thousands of chained 2017 dollars    216615470    220808767   \n","4                        Quantity index          100      101.936   \n","...                                 ...          ...          ...   \n","9529                     Quantity index          100      104.559   \n","9530               Thousands of dollars    681310123    730567674   \n","9531  Thousands of chained 2017 dollars   3797440495   3956948041   \n","9532                     Quantity index          100        104.2   \n","9533               Thousands of dollars   3797440495   4026578971   \n","\n","             2019         2020         2021         2022  \n","0     20692087000  20234074000  21407692000  21822037000  \n","1         105.507      103.171      109.156      111.268  \n","2     21521395000  21322950000  23594031000  25744108000  \n","3       224944577    222081439    231892626    235807320  \n","4         103.845      102.523      107.053       108.86  \n","...           ...          ...          ...          ...  \n","9529      109.552      109.329      116.661      119.324  \n","9530    776281078    781272363    880142487    974682556  \n","9531   4108525822   4048649569   4342903004   4385657757  \n","9532      108.192      106.615      114.364       115.49  \n","9533   4252235190   4254017130   4732878464   5066773749  \n","\n","[9534 rows x 14 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","with fs.open('ppp-loans-bucket/landing/gdp.csv') as f:\n","    gdp_df = pd.read_csv(f)\n","gdp_df"]},{"cell_type":"code","execution_count":25,"id":"e7100d4f","metadata":{"scrolled":true},"outputs":[{"data":{"text/plain":["GeoFIPS                   0\n","GeoName                   0\n","Region                    3\n","TableName                 0\n","LineCode                  0\n","IndustryClassification    0\n","Description               0\n","Unit                      0\n","2017                      0\n","2018                      0\n","2019                      0\n","2020                      0\n","2021                      0\n","2022                      0\n","dtype: int64"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["gdp_df.isnull().sum()"]},{"cell_type":"code","execution_count":26,"id":"3902587d","metadata":{},"outputs":[],"source":["gdp_df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":27,"id":"2fceca5a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame saved to gs://ppp-loans-bucket/cleaned/GDP.csv\n"]}],"source":["# Initialize GCS file system\n","fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","\n","# Define the GCS path for saving the file\n","gcs_path = 'gs://ppp-loans-bucket/cleaned/GDP.csv'\n","\n","# Save DataFrame to the \"cleaned\" folder in the GCS bucket\n","with fs.open(gcs_path, 'w') as f:\n","    gdp_df.to_csv(f, index=False)\n","\n","print(f\"DataFrame saved to {gcs_path}\")"]},{"cell_type":"markdown","id":"8b437301","metadata":{},"source":["# Cleaning NAICS data"]},{"cell_type":"code","execution_count":3,"id":"1bc01198","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Seq. No.</th>\n","      <th>2022 NAICS US   Code</th>\n","      <th>2022 NAICS US Title</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>11</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.0</td>\n","      <td>111</td>\n","      <td>Crop Production</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.0</td>\n","      <td>1111</td>\n","      <td>Oilseed and Grain Farming</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.0</td>\n","      <td>11111</td>\n","      <td>Soybean Farming</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2121</th>\n","      <td>2121.0</td>\n","      <td>9281</td>\n","      <td>National Security and International Affairs</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2122</th>\n","      <td>2122.0</td>\n","      <td>92811</td>\n","      <td>National Security</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2123</th>\n","      <td>2123.0</td>\n","      <td>928110</td>\n","      <td>National Security</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>2124.0</td>\n","      <td>92812</td>\n","      <td>International Affairs</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2125</th>\n","      <td>2125.0</td>\n","      <td>928120</td>\n","      <td>International Affairs</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2126 rows × 5 columns</p>\n","</div>"],"text/plain":["      Seq. No. 2022 NAICS US   Code  \\\n","0          NaN                  NaN   \n","1          1.0                   11   \n","2          2.0                  111   \n","3          3.0                 1111   \n","4          4.0                11111   \n","...        ...                  ...   \n","2121    2121.0                 9281   \n","2122    2122.0                92811   \n","2123    2123.0               928110   \n","2124    2124.0                92812   \n","2125    2125.0               928120   \n","\n","                               2022 NAICS US Title  Unnamed: 3 Unnamed: 4  \n","0                                              NaN         NaN        NaN  \n","1       Agriculture, Forestry, Fishing and Hunting         NaN        NaN  \n","2                                  Crop Production         NaN        NaN  \n","3                        Oilseed and Grain Farming         NaN        NaN  \n","4                                  Soybean Farming         NaN        NaN  \n","...                                            ...         ...        ...  \n","2121  National Security and International Affairs          NaN        NaN  \n","2122                            National Security          NaN        NaN  \n","2123                            National Security          NaN        NaN  \n","2124                        International Affairs          NaN        NaN  \n","2125                        International Affairs          NaN        NaN  \n","\n","[2126 rows x 5 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","with fs.open('ppp-loans-bucket/landing/NAICS_2-6-digit_2022_Codes.xlsx') as f:\n","    naics_df = pd.read_excel(f)\n","naics_df"]},{"cell_type":"code","execution_count":4,"id":"d538f49b","metadata":{},"outputs":[{"data":{"text/plain":["Seq. No.                   1\n","2022 NAICS US   Code       1\n","2022 NAICS US Title        1\n","Unnamed: 3              2126\n","Unnamed: 4              2125\n","dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["naics_df.isnull().sum()"]},{"cell_type":"code","execution_count":5,"id":"04b35c70","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Seq. No.', '2022 NAICS US   Code', '2022 NAICS US Title', 'Unnamed: 3',\n","       'Unnamed: 4'],\n","      dtype='object')\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2022 NAICS US   Code</th>\n","      <th>2022 NAICS US Title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>111</td>\n","      <td>Crop Production</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1111</td>\n","      <td>Oilseed and Grain Farming</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11111</td>\n","      <td>Soybean Farming</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  2022 NAICS US   Code                         2022 NAICS US Title\n","0                  NaN                                         NaN\n","1                   11  Agriculture, Forestry, Fishing and Hunting\n","2                  111                             Crop Production\n","3                 1111                   Oilseed and Grain Farming\n","4                11111                             Soybean Farming"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Dropping the \"Unnamed: 2\" column. It needs a bit of extra work to drop\n","\n","# Check the columns to verify the exact name\n","print(naics_df.columns)\n","\n","# Strip extra spaces from column names\n","naics_df.columns = naics_df.columns.str.strip()\n","\n","# Drop unnecessary columns\n","naics_df.drop('Unnamed: 3', axis=1, errors='ignore', inplace=True)\n","naics_df.drop('Unnamed: 4', axis=1, errors='ignore', inplace=True)\n","naics_df.drop('Seq. No.', axis=1, inplace=True)\n","# Display the first few rows\n","naics_df.head()"]},{"cell_type":"code","execution_count":6,"id":"37ac7f09","metadata":{},"outputs":[],"source":["#Drop null rows\n","naics_df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":33,"id":"5eb0db6e","metadata":{},"outputs":[],"source":["def naics_create_industry_type_col(df):\n","    \n","    if '2022 NAICS US   Code' in df.columns:\n","        df.rename(columns={'2022 NAICS US   Code': '2022 NAICS US Code'}, inplace=True)\n","    \n","    # Step 1: Extract the 2-digit NAICS code\n","    df[\"2_digit_code\"] = df[\"2022 NAICS US Code\"].astype(str).str[:2]\n","\n","    # Step 2: Create a mapping for 2-digit code to title\n","    mapping = df.loc[df[\"2022 NAICS US Code\"].astype(str).str.len() == 2, \n","                     [\"2022 NAICS US Code\", \"2022 NAICS US Title\"]]\n","    mapping = mapping.set_index(\"2022 NAICS US Code\")[\"2022 NAICS US Title\"].to_dict()\n","\n","    # Step 3: Use the 2-digit code to map the industry type\n","    df[\"industry_type\"] = df[\"2_digit_code\"].astype(int).map(mapping)\n","\n","    # Drop the helper column if no longer needed\n","    df = df.drop(columns=[\"2_digit_code\"])\n","    \n","    return df"]},{"cell_type":"code","execution_count":38,"id":"8160c2bf","metadata":{"scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2022 NAICS US Code</th>\n","      <th>2022 NAICS US Title</th>\n","      <th>industry_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>111</td>\n","      <td>Crop Production</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1111</td>\n","      <td>Oilseed and Grain Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11111</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>111110</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2121</th>\n","      <td>9281</td>\n","      <td>National Security and International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2122</th>\n","      <td>92811</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2123</th>\n","      <td>928110</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>92812</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2125</th>\n","      <td>928120</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2125 rows × 3 columns</p>\n","</div>"],"text/plain":["     2022 NAICS US Code                           2022 NAICS US Title  \\\n","1                    11    Agriculture, Forestry, Fishing and Hunting   \n","2                   111                               Crop Production   \n","3                  1111                     Oilseed and Grain Farming   \n","4                 11111                               Soybean Farming   \n","5                111110                               Soybean Farming   \n","...                 ...                                           ...   \n","2121               9281  National Security and International Affairs    \n","2122              92811                            National Security    \n","2123             928110                            National Security    \n","2124              92812                        International Affairs    \n","2125             928120                        International Affairs    \n","\n","                                   industry_type  \n","1     Agriculture, Forestry, Fishing and Hunting  \n","2     Agriculture, Forestry, Fishing and Hunting  \n","3     Agriculture, Forestry, Fishing and Hunting  \n","4     Agriculture, Forestry, Fishing and Hunting  \n","5     Agriculture, Forestry, Fishing and Hunting  \n","...                                          ...  \n","2121                       Public Administration  \n","2122                       Public Administration  \n","2123                       Public Administration  \n","2124                       Public Administration  \n","2125                       Public Administration  \n","\n","[2125 rows x 3 columns]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["naics_df = naics_create_industry_type_col(naics_df)\n","naics_df"]},{"cell_type":"code","execution_count":39,"id":"b0789b71","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame saved to gs://ppp-loans-bucket/cleaned/NAICS.csv\n"]}],"source":["# Initialize GCS file system\n","fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","\n","# Define the GCS path for saving the file\n","gcs_path = 'gs://ppp-loans-bucket/cleaned/NAICS.csv'\n","\n","# Save DataFrame to the \"cleaned\" folder in the GCS bucket\n","with fs.open(gcs_path, 'w') as f:\n","    naics_df.to_csv(f, index=False)\n","\n","print(f\"DataFrame saved to {gcs_path}\")"]},{"cell_type":"code","execution_count":null,"id":"c0a84e9a","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}