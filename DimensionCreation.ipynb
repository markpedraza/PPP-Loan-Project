{"cells":[{"cell_type":"code","execution_count":1,"id":"5b505ed8","metadata":{"scrolled":true},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-20241206-fix-gpd-schema-m.us-central1-f.c.cis4400-group-project-ppp.internal:44053\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f3db44e0c10>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"markdown","id":"db9a4d22","metadata":{},"source":["# Initial Setup (Install and import necessary packages)"]},{"cell_type":"code","execution_count":2,"id":"217f5e8e","metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gcsfs in /opt/conda/miniconda3/lib/python3.11/site-packages (2023.12.2.post1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (3.10.10)\n","Requirement already satisfied: decorator>4.1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (5.1.1)\n","Requirement already satisfied: fsspec==2023.12.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2023.12.2)\n","Requirement already satisfied: google-auth>=1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2.35.0)\n","Requirement already satisfied: google-auth-oauthlib in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (1.1.0)\n","Requirement already satisfied: google-cloud-storage in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2.13.0)\n","Requirement already satisfied: requests in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2.31.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.16.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.21.0)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.4.1)\n","Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.7.2)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (1.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (2024.8.30)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.65.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (4.24.4)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.25.0)\n","Requirement already satisfied: cffi>=1.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-crc32c<2.0dev,>=1.0->google-cloud-storage->gcsfs) (1.16.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n","Requirement already satisfied: propcache>=0.2.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.2.0)\n","Requirement already satisfied: pycparser in /opt/conda/miniconda3/lib/python3.11/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-cloud-storage->gcsfs) (2.21)\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0mCollecting openpyxl\n","  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n","Collecting et-xmlfile (from openpyxl)\n","  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n","Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n","\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m250.9/250.9 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n","\u001B[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n","Installing collected packages: et-xmlfile, openpyxl\n","Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install gcsfs\n","!pip install openpyxl"]},{"cell_type":"code","execution_count":3,"id":"42cc1fcc","metadata":{},"outputs":[],"source":["import pandas as pd\n","import gcsfs\n","import calendar\n","from google.cloud import storage\n","from google.cloud.exceptions import NotFound\n","from pyspark.sql import Row\n","from pyspark.sql.functions import col, lower, instr, date_format, split, rand, regexp_replace, trim\n","from pyspark.sql.functions import monotonically_increasing_id # virtually the same as factorize() from pandas."]},{"cell_type":"code","execution_count":4,"id":"f7c74a1d","metadata":{},"outputs":[],"source":["# Define the bucket we will save to. Many areas will reference this variable later\n","bucket = \"ppp-loans-bucket\""]},{"cell_type":"markdown","id":"657493ba","metadata":{},"source":["# Read clean data into appropriate dataframes"]},{"cell_type":"code","execution_count":5,"id":"93acaa5e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["ppp_df = spark.read.parquet(\"gs://ppp-loans-bucket/cleaned/part-*\")#.sample(fraction=0.001,seed=42)"]},{"cell_type":"code","execution_count":6,"id":"7dd1f5fc","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["10406068"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["ppp_df.count()"]},{"cell_type":"code","execution_count":7,"id":"2cbf2fc0","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>GeoFIPS</th>\n","      <th>GeoName</th>\n","      <th>Region</th>\n","      <th>TableName</th>\n","      <th>LineCode</th>\n","      <th>IndustryClassification</th>\n","      <th>Description</th>\n","      <th>Unit</th>\n","      <th>2017</th>\n","      <th>2018</th>\n","      <th>2019</th>\n","      <th>2020</th>\n","      <th>2021</th>\n","      <th>2022</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>216615470</td>\n","      <td>220808767</td>\n","      <td>224944577</td>\n","      <td>222081439</td>\n","      <td>231892626</td>\n","      <td>235807320</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>101.936</td>\n","      <td>103.845</td>\n","      <td>102.523</td>\n","      <td>107.053</td>\n","      <td>108.86</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>216615470</td>\n","      <td>226263784</td>\n","      <td>234526408</td>\n","      <td>235118280</td>\n","      <td>257986516</td>\n","      <td>281569005</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1001</td>\n","      <td>Autauga, AL</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>1762558</td>\n","      <td>1787534</td>\n","      <td>1730861</td>\n","      <td>1722438</td>\n","      <td>1727818</td>\n","      <td>1929264</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1001</td>\n","      <td>Autauga, AL</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>101.417</td>\n","      <td>98.202</td>\n","      <td>97.724</td>\n","      <td>98.029</td>\n","      <td>109.458</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9526</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>104.559</td>\n","      <td>109.552</td>\n","      <td>109.329</td>\n","      <td>116.661</td>\n","      <td>119.324</td>\n","    </tr>\n","    <tr>\n","      <th>9527</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>681310123</td>\n","      <td>730567674</td>\n","      <td>776281078</td>\n","      <td>781272363</td>\n","      <td>880142487</td>\n","      <td>974682556</td>\n","    </tr>\n","    <tr>\n","      <th>9528</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>3797440495</td>\n","      <td>3956948041</td>\n","      <td>4108525822</td>\n","      <td>4048649569</td>\n","      <td>4342903004</td>\n","      <td>4385657757</td>\n","    </tr>\n","    <tr>\n","      <th>9529</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>104.2</td>\n","      <td>108.192</td>\n","      <td>106.615</td>\n","      <td>114.364</td>\n","      <td>115.49</td>\n","    </tr>\n","    <tr>\n","      <th>9530</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>3797440495</td>\n","      <td>4026578971</td>\n","      <td>4252235190</td>\n","      <td>4254017130</td>\n","      <td>4732878464</td>\n","      <td>5066773749</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9531 rows × 14 columns</p>\n","</div>"],"text/plain":["      GeoFIPS         GeoName  Region TableName  LineCode  \\\n","0        1000         Alabama     5.0    CAGDP1         1   \n","1        1000         Alabama     5.0    CAGDP1         2   \n","2        1000         Alabama     5.0    CAGDP1         3   \n","3        1001     Autauga, AL     5.0    CAGDP1         1   \n","4        1001     Autauga, AL     5.0    CAGDP1         2   \n","...       ...             ...     ...       ...       ...   \n","9526    97000  Rocky Mountain     7.0    CAGDP1         2   \n","9527    97000  Rocky Mountain     7.0    CAGDP1         3   \n","9528    98000        Far West     8.0    CAGDP1         1   \n","9529    98000        Far West     8.0    CAGDP1         2   \n","9530    98000        Far West     8.0    CAGDP1         3   \n","\n","     IndustryClassification  \\\n","0                       ...   \n","1                       ...   \n","2                       ...   \n","3                       ...   \n","4                       ...   \n","...                     ...   \n","9526                    ...   \n","9527                    ...   \n","9528                    ...   \n","9529                    ...   \n","9530                    ...   \n","\n","                                            Description  \\\n","0         Real GDP (thousands of chained 2017 dollars)    \n","1             Chain-type quantity indexes for real GDP    \n","2     Current-dollar GDP (thousands of current dolla...   \n","3         Real GDP (thousands of chained 2017 dollars)    \n","4             Chain-type quantity indexes for real GDP    \n","...                                                 ...   \n","9526          Chain-type quantity indexes for real GDP    \n","9527  Current-dollar GDP (thousands of current dolla...   \n","9528      Real GDP (thousands of chained 2017 dollars)    \n","9529          Chain-type quantity indexes for real GDP    \n","9530  Current-dollar GDP (thousands of current dolla...   \n","\n","                                   Unit        2017        2018        2019  \\\n","0     Thousands of chained 2017 dollars   216615470   220808767   224944577   \n","1                        Quantity index         100     101.936     103.845   \n","2                  Thousands of dollars   216615470   226263784   234526408   \n","3     Thousands of chained 2017 dollars     1762558     1787534     1730861   \n","4                        Quantity index         100     101.417      98.202   \n","...                                 ...         ...         ...         ...   \n","9526                     Quantity index         100     104.559     109.552   \n","9527               Thousands of dollars   681310123   730567674   776281078   \n","9528  Thousands of chained 2017 dollars  3797440495  3956948041  4108525822   \n","9529                     Quantity index         100       104.2     108.192   \n","9530               Thousands of dollars  3797440495  4026578971  4252235190   \n","\n","            2020        2021        2022  \n","0      222081439   231892626   235807320  \n","1        102.523     107.053      108.86  \n","2      235118280   257986516   281569005  \n","3        1722438     1727818     1929264  \n","4         97.724      98.029     109.458  \n","...          ...         ...         ...  \n","9526     109.329     116.661     119.324  \n","9527   781272363   880142487   974682556  \n","9528  4048649569  4342903004  4385657757  \n","9529     106.615     114.364      115.49  \n","9530  4254017130  4732878464  5066773749  \n","\n","[9531 rows x 14 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","with fs.open(\"ppp-loans-bucket/cleaned/GDP.csv\") as f:\n","    gdp_df = pd.read_csv(f)\n","gdp_df"]},{"cell_type":"code","execution_count":8,"id":"233ba7fd","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2022 NAICS US Code</th>\n","      <th>2022 NAICS US Title</th>\n","      <th>industry_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111</td>\n","      <td>Crop Production</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1111</td>\n","      <td>Oilseed and Grain Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11111</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>111110</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2120</th>\n","      <td>9281</td>\n","      <td>National Security and International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2121</th>\n","      <td>92811</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2122</th>\n","      <td>928110</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2123</th>\n","      <td>92812</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>928120</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2125 rows × 3 columns</p>\n","</div>"],"text/plain":["     2022 NAICS US Code                           2022 NAICS US Title  \\\n","0                    11    Agriculture, Forestry, Fishing and Hunting   \n","1                   111                               Crop Production   \n","2                  1111                     Oilseed and Grain Farming   \n","3                 11111                               Soybean Farming   \n","4                111110                               Soybean Farming   \n","...                 ...                                           ...   \n","2120               9281  National Security and International Affairs    \n","2121              92811                            National Security    \n","2122             928110                            National Security    \n","2123              92812                        International Affairs    \n","2124             928120                        International Affairs    \n","\n","                                   industry_type  \n","0     Agriculture, Forestry, Fishing and Hunting  \n","1     Agriculture, Forestry, Fishing and Hunting  \n","2     Agriculture, Forestry, Fishing and Hunting  \n","3     Agriculture, Forestry, Fishing and Hunting  \n","4     Agriculture, Forestry, Fishing and Hunting  \n","...                                          ...  \n","2120                       Public Administration  \n","2121                       Public Administration  \n","2122                       Public Administration  \n","2123                       Public Administration  \n","2124                       Public Administration  \n","\n","[2125 rows x 3 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","with fs.open('ppp-loans-bucket/cleaned/NAICS.csv') as f:\n","    naics_df = pd.read_csv(f)\n","naics_df"]},{"cell_type":"markdown","id":"584f82a9","metadata":{},"source":["# Checking columns"]},{"cell_type":"code","execution_count":9,"id":"803494d1","metadata":{},"outputs":[{"data":{"text/plain":["['LoanNumber',\n"," 'DateApproved',\n"," 'SBAOfficeCode',\n"," 'ProcessingMethod',\n"," 'BorrowerName',\n"," 'BorrowerAddress',\n"," 'BorrowerCity',\n"," 'BorrowerState',\n"," 'BorrowerZip',\n"," 'LoanStatusDate',\n"," 'LoanStatus',\n"," 'Term',\n"," 'SBAGuarantyPercentage',\n"," 'InitialApprovalAmount',\n"," 'CurrentApprovalAmount',\n"," 'UndisbursedAmount',\n"," 'FranchiseName',\n"," 'ServicingLenderLocationID',\n"," 'ServicingLenderName',\n"," 'ServicingLenderAddress',\n"," 'ServicingLenderCity',\n"," 'ServicingLenderState',\n"," 'ServicingLenderZip',\n"," 'RuralUrbanIndicator',\n"," 'HubzoneIndicator',\n"," 'LMIIndicator',\n"," 'BusinessAgeDescription',\n"," 'ProjectCity',\n"," 'ProjectCountyName',\n"," 'ProjectState',\n"," 'ProjectZip',\n"," 'CD',\n"," 'JobsReported',\n"," 'NAICSCode',\n"," 'Race',\n"," 'Ethnicity',\n"," 'PAYROLL_PROCEED',\n"," 'BusinessType',\n"," 'OriginatingLenderLocationID',\n"," 'OriginatingLender',\n"," 'OriginatingLenderCity',\n"," 'OriginatingLenderState',\n"," 'Gender',\n"," 'Veteran',\n"," 'NonProfit',\n"," 'ForgivenessAmount',\n"," 'ForgivenessDate',\n"," 'forgiveness_date',\n"," 'date_approved',\n"," 'loan_status_date']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["ppp_df.columns"]},{"cell_type":"code","execution_count":10,"id":"433c3628","metadata":{},"outputs":[{"data":{"text/plain":["Index(['GeoFIPS', 'GeoName', 'Region', 'TableName', 'LineCode',\n","       'IndustryClassification', 'Description', 'Unit', '2017', '2018', '2019',\n","       '2020', '2021', '2022'],\n","      dtype='object')"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["gdp_df.columns"]},{"cell_type":"code","execution_count":11,"id":"5369e248","metadata":{},"outputs":[{"data":{"text/plain":["Index(['2022 NAICS US Code', '2022 NAICS US Title', 'industry_type'], dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["naics_df.columns"]},{"cell_type":"markdown","id":"db6cb13d","metadata":{},"source":["# Reformatting"]},{"cell_type":"code","execution_count":12,"id":"f562ef62","metadata":{},"outputs":[],"source":["# Changes a list of columns to a certain datatype. This is for PySpark dataframes.\n","# You give it... \n","#  1. The dataframe you want to modify\n","#  2. The list of strings for the name of columns you want to be modified\n","#  3. The datetype you want to modify them to\n","\n","def change_cols_to_type(df, list_of_columns, data_type):\n","    for column in list_of_columns:\n","        df = df.withColumn(column, df[column].cast(data_type))\n","    return df"]},{"cell_type":"code","execution_count":13,"id":"7d510662","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- LoanNumber: long (nullable = true)\n"," |-- DateApproved: string (nullable = true)\n"," |-- SBAOfficeCode: integer (nullable = true)\n"," |-- ProcessingMethod: string (nullable = true)\n"," |-- BorrowerName: string (nullable = true)\n"," |-- BorrowerAddress: string (nullable = true)\n"," |-- BorrowerCity: string (nullable = true)\n"," |-- BorrowerState: string (nullable = true)\n"," |-- BorrowerZip: string (nullable = true)\n"," |-- LoanStatusDate: string (nullable = true)\n"," |-- LoanStatus: string (nullable = true)\n"," |-- Term: string (nullable = true)\n"," |-- SBAGuarantyPercentage: float (nullable = true)\n"," |-- InitialApprovalAmount: float (nullable = true)\n"," |-- CurrentApprovalAmount: float (nullable = true)\n"," |-- UndisbursedAmount: float (nullable = true)\n"," |-- FranchiseName: string (nullable = true)\n"," |-- ServicingLenderLocationID: long (nullable = true)\n"," |-- ServicingLenderName: string (nullable = true)\n"," |-- ServicingLenderAddress: string (nullable = true)\n"," |-- ServicingLenderCity: string (nullable = true)\n"," |-- ServicingLenderState: string (nullable = true)\n"," |-- ServicingLenderZip: string (nullable = true)\n"," |-- RuralUrbanIndicator: string (nullable = true)\n"," |-- HubzoneIndicator: string (nullable = true)\n"," |-- LMIIndicator: string (nullable = true)\n"," |-- BusinessAgeDescription: string (nullable = true)\n"," |-- ProjectCity: string (nullable = true)\n"," |-- ProjectCountyName: string (nullable = true)\n"," |-- ProjectState: string (nullable = true)\n"," |-- ProjectZip: string (nullable = true)\n"," |-- CD: string (nullable = true)\n"," |-- JobsReported: float (nullable = true)\n"," |-- NAICSCode: string (nullable = true)\n"," |-- Race: string (nullable = true)\n"," |-- Ethnicity: string (nullable = true)\n"," |-- PAYROLL_PROCEED: string (nullable = true)\n"," |-- BusinessType: string (nullable = true)\n"," |-- OriginatingLenderLocationID: long (nullable = true)\n"," |-- OriginatingLender: string (nullable = true)\n"," |-- OriginatingLenderCity: string (nullable = true)\n"," |-- OriginatingLenderState: string (nullable = true)\n"," |-- Gender: string (nullable = true)\n"," |-- Veteran: string (nullable = true)\n"," |-- NonProfit: string (nullable = true)\n"," |-- ForgivenessAmount: float (nullable = true)\n"," |-- ForgivenessDate: string (nullable = true)\n"," |-- forgiveness_date: date (nullable = true)\n"," |-- date_approved: date (nullable = true)\n"," |-- loan_status_date: date (nullable = true)\n","\n"]}],"source":["ppp_df_cols_to_float = [\"InitialApprovalAmount\", \"CurrentApprovalAmount\",\n","                \"UndisbursedAmount\", \"ForgivenessAmount\", \n","                 \"SBAGuarantyPercentage\", \"JobsReported\"]\n","ppp_df_cols_to_long = [\"ServicingLenderLocationID\", \"OriginatingLenderLocationID\"]\n","\n","ppp_df = change_cols_to_type(ppp_df, ppp_df_cols_to_float, \"float\")\n","ppp_df = change_cols_to_type(ppp_df, ppp_df_cols_to_long, \"long\")\n","\n","#naics_df['2022 NAICS US Code'] = naics_df['2022 NAICS US Code'].astype(int)\n","\n","ppp_df.printSchema()"]},{"cell_type":"markdown","id":"0f71c0a2","metadata":{},"source":["# Function that creates ID's for columns in a Spark Dataframe"]},{"cell_type":"code","execution_count":14,"id":"9b6f012a","metadata":{},"outputs":[],"source":["def create_ids(df,id_column_name=None):\n","    #Transforms PySpark dataframe\n","    if isinstance(df, PySparkDataFrame):\n","        print(\"Transforming PySpark DataFrame...\")\n","        \n","        if id_column_name is None:\n","            id_column_name = \"id\"\n","        \n","        # Extract the original schema\n","        original_schema = df.schema\n","\n","        # Add an ID column using zipWithIndex\n","        df_with_index = (\n","            df.rdd\n","            .zipWithIndex()  # Add an index to each row\n","            .map(lambda x: Row(**dict(x[0].asDict(), id=x[1])))  # Add 'id' to each row\n","        )\n","\n","        # Define the new schema with the ID column added\n","        new_schema = original_schema.add(id_column_name, \"long\")\n","\n","        # Create a new DataFrame with the updated schema\n","        df_with_index = spark.createDataFrame(df_with_index, schema=new_schema)\n","        \n","        print(\"Completed transforming PySpark DataFrame.\")\n","        return df_with_index\n","    \n","    #No valid dataframe found\n","    else:\n","        print(\"ERROR: INVALID DATAFRAME - NO PROCEDURE APPLIED.\")\n","        print(\"Did you try inputting a PySpark Dataframe?\")"]},{"cell_type":"markdown","id":"5040b408","metadata":{},"source":["# Function to turn column names to snake_case"]},{"cell_type":"code","execution_count":15,"id":"6e73cb70","metadata":{},"outputs":[],"source":["#Turns any columns that has TheseColumnsNames to these_column_names\n","import re\n","from pyspark.sql import DataFrame as PySparkDataFrame\n","def name_to_snake_case(name):\n","    # Add underscores before capital letters, then convert to lowercase\n","    return re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()\n","\n","#Takes in any type of dataframe and turns its columns into snake_case\n","def df_to_snake_case(df):\n","    \n","    #Transforms PySpark dataframe\n","    if isinstance(df, PySparkDataFrame):\n","        print(\"Transforming PySpark DataFrame...\")\n","        # Rename all columns to snake_case\n","        snake_case_columns = [name_to_snake_case(col) for col in df.columns]\n","        df_snake_case = df.toDF(*snake_case_columns)\n","        print(\"Completed transforming PySpark DataFrame.\")\n","        return df_snake_case\n","    \n","    #Transforms Pandas dataframe\n","    elif isinstance(df, pd.DataFrame):\n","        print(\"Transforming Pandas DataFrame...\")\n","        # Rename all columns to snake_case\n","        df.columns = [name_to_snake_case(col) for col in df.columns]\n","        print(\"Completed transforming Pandas DataFrame.\")\n","        return df\n","    \n","    #No valid dataframe found\n","    else:\n","        print(\"ERROR: INVALID DATAFRAME - NO PROCEDURE APPLIED\")\n"]},{"cell_type":"code","execution_count":16,"id":"e42db538","metadata":{},"outputs":[],"source":["# initialize array. Append all dims and tables here. At the end, we loop through this list to save all dataframes.\n","tables = []"]},{"cell_type":"code","execution_count":17,"id":"ed97427f","metadata":{},"outputs":[],"source":["# Function to check how unique a column is. This will be used to verify all ID's in an ID column are unique.\n","def check_uniqueness(df, col_name):\n","    if isinstance(df, PySparkDataFrame):\n","        total_count = df.count()\n","        distinct_count = df.select(col_name).distinct().count()\n","    elif isinstance(df, pd.DataFrame):\n","        total_count = len(df)\n","        distinct_count = df[col_name].nunique()\n","\n","    if total_count == distinct_count:\n","        print(f\"The column '{col_name}' contains all unique values.\")\n","    else:\n","        print(f\"The column '{col_name}' contains duplicates. Total rows: {total_count}, Distinct rows: {distinct_count}\")"]},{"cell_type":"markdown","id":"428d8ec1","metadata":{},"source":["# Dim Borrower"]},{"cell_type":"code","execution_count":18,"id":"f1fc4c36","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----------+--------------------+--------------------+-----------------+--------------+------------+--------------------+------------------------+--------------------+-----------------+--------------------+------------+-----------+----------+\n","|borrower_id|       borrower_name|    borrower_address|    borrower_city|borrower_state|borrower_zip|      franchise_name|business_age_description|                race|        ethnicity|       business_type|      gender|    veteran|non_profit|\n","+-----------+--------------------+--------------------+-----------------+--------------+------------+--------------------+------------------------+--------------------+-----------------+--------------------+------------+-----------+----------+\n","| 7617718505|LOCUM TENENS PART...|145 Technology Pk...|Peachtree Corners|            GA|  30092-3536|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 4948677304|CARITAS MEDICAL C...|      105 N PARK TRL|      STOCKBRIDGE|            GA|  30281-7432|                NULL|    Existing or more ...|Black or African ...|Unknown/NotStated|         Corporation|  Male Owned|Non-Veteran|      NULL|\n","| 1158507802| VERISOLUTIONS, INC.|  75 5TH ST STE 3120|          ATLANTA|            GA|  30308-1078|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|         Corporation|  Unanswered| Unanswered|      NULL|\n","| 4654547000|VICKERY ROSE RETI...|295 E. Crossville...|          ROSWELL|            GA|  30075-3027|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 5551147000|GEORGIA CARE GROU...|4480 Valnorth Dri...|         Valdosta|            GA|       31602|Home Instead/Home...|    New Business or 2...|          Unanswered|Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 7253827004|SRJ ARCHITECTS, INC.|    1108 MARYLAND DR|           ALBANY|            GA|  31707-3879|                NULL|    Existing or more ...|               White|Unknown/NotStated|         Corporation|  Unanswered| Unanswered|      NULL|\n","| 6901687004|GAINESVILLE REGIO...|       743 SPRING ST|      GAINESVILLE|            GA|  30501-3715|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|         Corporation|  Unanswered| Unanswered|      NULL|\n","| 1246748310|AIRTIGHT DESIGN, LLC|659 Auburn Ave NE...|          Atlanta|            GA|  30312-1976|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 9916187101| SCIENTIFIC TURF INC|248 ROSE DR Suite...|        BRUNSWICK|            GA|  31520-2944|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|         Corporation|  Unanswered| Unanswered|      NULL|\n","| 8749968506|ACORN THERMAL SER...|306 Downing Creek...|           Canton|            GA|  30114-6587|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|Limited Liability...|  Unanswered| Unanswered|      NULL|\n","| 6475217304|MCDONOUGH URBAN A...|   1970 Jonesboro rd|        MCDONOUGH|            GA|       30253|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 2945007101|ATHENS GASTROENTE...|3320 OLD JEFFERSO...|           ATHENS|            GA|       30607|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|         Corporation|  Unanswered| Unanswered|      NULL|\n","| 5228487204|CROISSANT BAKERY LLC|6514 warren dr su...|         Norcross|            GA|       30093|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|Limited  Liabilit...|  Male Owned|Non-Veteran|      NULL|\n","| 5834597006|GODLEY STATION AN...|    127 Canal Street|           POOLER|            GA|  31322-4016|                NULL|              Unanswered|          Unanswered|Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 6115508300|PROFESSIONAL PRIC...|3535 Roswell Rd S...|         Marietta|            GA|  30062-8828|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|         Corporation|  Male Owned| Unanswered|      NULL|\n","| 6833347102| WOMEN WHO CODE, INC|695 PYLANT ST NE ...|          ATLANTA|            GA|  30306-3728|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|         Corporation|Female Owned|Non-Veteran|      NULL|\n","| 7757507104|COMNEXIA CORPORATION|590 WEST CROSSVIL...|          ROSWELL|            GA|  30075-2506|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|         Corporation|  Male Owned| Unanswered|      NULL|\n","| 9076867002|CORRECTIONAL RESO...|        123 DAM ROAD|          JACKSON|            GA|  30233-4823|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|Subchapter S Corp...|  Unanswered| Unanswered|      NULL|\n","| 9536127103|PROFESSIONAL PRIC...|     3535 ROSWELL RD|         MARIETTA|            GA|  30062-8828|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|         Corporation|  Unanswered| Unanswered|      NULL|\n","| 9923628510|TEMPLE EMANU-EL O...|    1580 Spalding Dr|          Atlanta|            GA|  30350-4212|                NULL|    Existing or more ...|          Unanswered|Unknown/NotStated|Non-Profit Organi...|  Unanswered| Unanswered|         Y|\n","+-----------+--------------------+--------------------+-----------------+--------------+------------+--------------------+------------------------+--------------------+-----------------+--------------------+------------+-----------+----------+\n","only showing top 20 rows\n","\n"]},{"data":{"text/plain":["['borrower_id',\n"," 'borrower_name',\n"," 'borrower_address',\n"," 'borrower_city',\n"," 'borrower_state',\n"," 'borrower_zip',\n"," 'franchise_name',\n"," 'business_age_description',\n"," 'race',\n"," 'ethnicity',\n"," 'business_type',\n"," 'gender',\n"," 'veteran',\n"," 'non_profit']"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["#Create Dim\n","dim_borrower = ppp_df.select(\"LoanNumber\",\"BorrowerName\",\"BorrowerAddress\",\n","                            \"BorrowerCity\",\"BorrowerState\",\"BorrowerZip\",\n","                            \"FranchiseName\",\"BusinessAgeDescription\",\n","                            \"Race\",\"Ethnicity\",\"BusinessType\",\"Gender\",\n","                            \"Veteran\",\"NonProfit\")\n","\n","#Fix Names\n","dim_borrower = dim_borrower.withColumnRenamed(\"LoanNumber\",\"borrower_id\")\n","dim_borrower = df_to_snake_case(dim_borrower)\n","\n","#Add to tables\n","tables.append([dim_borrower,\"dim_borrower\"])\n","\n","#Show\n","dim_borrower.show()\n","dim_borrower.columns"]},{"cell_type":"markdown","id":"2f0290a4","metadata":{},"source":["# Dim SBA office"]},{"cell_type":"code","execution_count":19,"id":"01682035","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 6:==============================================>           (8 + 2) / 10]\r"]},{"name":"stdout","output_type":"stream","text":["Transforming Pandas DataFrame...\n","Completed transforming Pandas DataFrame.\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SBA_office_code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>876</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>914</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>811</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>912</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>206</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>508</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>1086</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>172</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>9030</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>150</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>76 rows × 1 columns</p>\n","</div>"],"text/plain":["    SBA_office_code\n","0               876\n","1               914\n","2               811\n","3               912\n","4               206\n","..              ...\n","71              508\n","72             1086\n","73              172\n","74             9030\n","75              150\n","\n","[76 rows x 1 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["#Create Dim\n","dim_SBA_office = ppp_df.select(\"SBAOfficeCode\").distinct().toPandas()\n","\n","#Fix Names\n","dim_SBA_office = df_to_snake_case(dim_SBA_office)\n","dim_SBA_office.rename(columns={'s_b_a_office_code':'SBA_office_code'}, inplace=True)\n","\n","#Add to tables\n","tables.append([dim_SBA_office,\"dim_SBA_office\"])\n","\n","#Show\n","dim_SBA_office"]},{"cell_type":"markdown","id":"c020973f","metadata":{},"source":["# Dim Processing Method"]},{"cell_type":"code","execution_count":20,"id":"2499da32","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 11:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["Transforming Pandas DataFrame...\n","Completed transforming Pandas DataFrame.\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>processing_method</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PPP</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PPS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  processing_method\n","0               PPP\n","1               PPS"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["#Create Dim\n","dim_processing_method = ppp_df.select(\"ProcessingMethod\").distinct().toPandas()\n","\n","#Fix Names\n","dim_processing_method = df_to_snake_case(dim_processing_method)\n","\n","#Add to tables\n","tables.append([dim_processing_method,\"dim_processing_method\"])\n","\n","#Show\n","dim_processing_method"]},{"cell_type":"markdown","id":"b6bf6b3d","metadata":{},"source":["# Dim Originating Lender"]},{"cell_type":"code","execution_count":21,"id":"5f738cf0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n","+------------------------------+--------------------+-----------------------+------------------------+\n","|originating_lender_location_id|  originating_lender|originating_lender_city|originating_lender_state|\n","+------------------------------+--------------------+-----------------------+------------------------+\n","|                        434059|         Primis Bank|           TAPPAHANNOCK|                      VA|\n","|                        225134|         Truist Bank|              CHARLOTTE|                      NC|\n","|                         58036|    Fifth Third Bank|             CINCINNATI|                      OH|\n","|                         42290|Union Bank and Tr...|                LINCOLN|                      NE|\n","|                        455644|Live Oak Banking ...|             WILMINGTON|                      NC|\n","|                        437877|Flint Community Bank|                 ALBANY|                      GA|\n","|                        434107|Peach State Bank ...|            Gainesville|                      GA|\n","|                         81965|Affinity Bank, Na...|              Covington|                      GA|\n","|                         19668|Citizens Bank of ...|           SANDERSVILLE|                      GA|\n","|                        225134|         Truist Bank|              CHARLOTTE|                      NC|\n","|                         48270|JPMorgan Chase Ba...|               COLUMBUS|                      OH|\n","|                        119947|      HomeTrust Bank|                Suwanee|                      GA|\n","|                        225134|         Truist Bank|              CHARLOTTE|                      NC|\n","|                        250423|  First Chatham Bank|               SAVANNAH|                      GA|\n","|                        527106|    Loyal Trust Bank|            JOHNS CREEK|                      GA|\n","|                         59698|         Umpqua Bank|               ROSEBURG|                      OR|\n","|                        434138|    ServisFirst Bank|             BIRMINGHAM|                      AL|\n","|                         88011|Heritage Bank, A ...|              Jonesboro|                      GA|\n","|                        527106|    Loyal Trust Bank|            JOHNS CREEK|                      GA|\n","|                        225134|         Truist Bank|              CHARLOTTE|                      NC|\n","+------------------------------+--------------------+-----------------------+------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["#Create Dim\n","dim_originating_lender = ppp_df.select(\"OriginatingLenderLocationID\",\n","                                      \"OriginatingLender\",\"OriginatingLenderCity\",\n","                                      \"OriginatingLenderState\")\n","\n","#Fix Names\n","dim_originating_lender = df_to_snake_case(dim_originating_lender)\n","dim_originating_lender = dim_originating_lender.withColumnRenamed(\"originating_lender_location_i_d\",\"originating_lender_location_id\")\n","\n","#Add to tables\n","tables.append([dim_originating_lender,\"dim_originating_lender\"])\n","\n","#Show\n","dim_originating_lender.show()"]},{"cell_type":"markdown","id":"9846d215","metadata":{},"source":["# Dim Servicing Lender"]},{"cell_type":"code","execution_count":22,"id":"5f383733","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n","+-----------------------------+---------------------+------------------------+---------------------+----------------------+--------------------+\n","|servicing_lender_location_i_d|servicing_lender_name|servicing_lender_address|servicing_lender_city|servicing_lender_state|servicing_lender_zip|\n","+-----------------------------+---------------------+------------------------+---------------------+----------------------+--------------------+\n","|                       434059|          Primis Bank|         307 Church Lane|         TAPPAHANNOCK|                    VA|               22560|\n","|                       225134|          Truist Bank|          214 N Tryon St|            CHARLOTTE|                    NC|          28202-1078|\n","|                        58036|     Fifth Third Bank|      38 Fountain Sq Plz|           CINCINNATI|                    OH|               45263|\n","|                        42290| Union Bank and Tr...|          3643 S 48th St|              LINCOLN|                    NE|          68506-4341|\n","|                       455644| Live Oak Banking ...|         1741 Tiburon Dr|           WILMINGTON|                    NC|          28403-6244|\n","|                       437877| Flint Community Bank|        2910 Meredyth Dr|               ALBANY|                    GA|          31721-1589|\n","|                       434107| Peach State Bank ...|     121, EE Butler Pkwy|          Gainesville|                    GA|               30501|\n","|                        81965| Affinity Bank, Na...|            3175 Hwy 278|            Covington|                    GA|               30014|\n","|                        19668| Citizens Bank of ...|         132 S Harris St|         SANDERSVILLE|                    GA|          31082-1702|\n","|                       225134|          Truist Bank|          214 N Tryon St|            CHARLOTTE|                    NC|          28202-1078|\n","|                        48270| JPMorgan Chase Ba...|       1111 Polaris Pkwy|             COLUMBUS|                    OH|          43240-2031|\n","|                        77468|       HomeTrust Bank|           10 Woodfin St|            ASHEVILLE|                    NC|          28801-3022|\n","|                       225134|          Truist Bank|          214 N Tryon St|            CHARLOTTE|                    NC|          28202-1078|\n","|                       250423|   First Chatham Bank|          111 Barnard St|             SAVANNAH|                    GA|          31401-3219|\n","|                       527106|     Loyal Trust Bank|    11675 Medlock Bri...|          JOHNS CREEK|                    GA|          30097-1565|\n","|                        59698|          Umpqua Bank|    445 SE Main St, F...|             ROSEBURG|                    OR|          97470-4934|\n","|                       434138|     ServisFirst Bank|    2500 Woodcrest Place|           BIRMINGHAM|                    AL|          35209-1374|\n","|                       120708|       The First Bank|       6480 Hwy 98, West|          HATTIESBURG|                    MS|               39402|\n","|                       527106|     Loyal Trust Bank|    11675 Medlock Bri...|          JOHNS CREEK|                    GA|          30097-1565|\n","|                       225134|          Truist Bank|          214 N Tryon St|            CHARLOTTE|                    NC|          28202-1078|\n","+-----------------------------+---------------------+------------------------+---------------------+----------------------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["#Create Dim\n","dim_servicing_lender = ppp_df.select('ServicingLenderLocationID', 'ServicingLenderName',\n","                                     'ServicingLenderAddress', 'ServicingLenderCity', \n","                                     'ServicingLenderState','ServicingLenderZip')\n","\n","#Fix Names\n","dim_servicing_lender = df_to_snake_case(dim_servicing_lender)\n","\n","#Add to tables\n","tables.append([dim_servicing_lender,\"dim_servicing_lender\"])\n","\n","#Show\n","dim_servicing_lender.show()"]},{"cell_type":"markdown","id":"b4ac5411","metadata":{},"source":["# Dim Date"]},{"cell_type":"code","execution_count":23,"id":"66b509cf","metadata":{"scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>date_id</th>\n","      <th>year_number</th>\n","      <th>month_number</th>\n","      <th>day_number</th>\n","      <th>week_number</th>\n","      <th>week_of_month</th>\n","      <th>week_of_year</th>\n","      <th>month_name</th>\n","      <th>day_name</th>\n","      <th>timestamp_isoformat</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-01-01</td>\n","      <td>20170101</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Sunday</td>\n","      <td>2017-01-01T00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-01-02</td>\n","      <td>20170102</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>01</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Monday</td>\n","      <td>2017-01-02T00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-01-03</td>\n","      <td>20170103</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>01</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Tuesday</td>\n","      <td>2017-01-03T00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-01-04</td>\n","      <td>20170104</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>01</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Wednesday</td>\n","      <td>2017-01-04T00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-01-05</td>\n","      <td>20170105</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>01</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Thursday</td>\n","      <td>2017-01-05T00:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        date   date_id  year_number  month_number  day_number week_number  \\\n","0 2017-01-01  20170101         2017             1           1          52   \n","1 2017-01-02  20170102         2017             1           2          01   \n","2 2017-01-03  20170103         2017             1           3          01   \n","3 2017-01-04  20170104         2017             1           4          01   \n","4 2017-01-05  20170105         2017             1           5          01   \n","\n","   week_of_month week_of_year month_name   day_name  timestamp_isoformat  \n","0              1           01    January     Sunday  2017-01-01T00:00:00  \n","1              1           01    January     Monday  2017-01-02T00:00:00  \n","2              1           01    January    Tuesday  2017-01-03T00:00:00  \n","3              1           01    January  Wednesday  2017-01-04T00:00:00  \n","4              1           01    January   Thursday  2017-01-05T00:00:00  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["def week_of_month(dt):\n","    year = dt.year\n","    month = dt.month\n","    day = dt.day\n","    \n","    cal = calendar.monthcalendar(year,month)\n","    week_number = (day - 1) // 7 + 1\n","    return week_number\n","\n","    \n","#Create Dim\n","start_date = pd.to_datetime(\"2017-01-01\")\n","end_date = pd.to_datetime(\"2022-12-31\")\n","\n","dim_date = pd.DataFrame({\"date\": pd.date_range(start_date, end_date, freq=\"D\")})\n","\n","dim_date['date_id'] = dim_date['date'].dt.strftime('%Y%m%d')\n","dim_date['year_number'] = dim_date['date'].dt.year\n","dim_date['month_number'] = dim_date['date'].dt.month\n","dim_date['day_number'] = dim_date['date'].dt.day\n","dim_date['week_number'] = dim_date['date'].dt.strftime('%V')\n","dim_date['week_of_month'] = dim_date['date'].apply(week_of_month)\n","dim_date['week_of_year'] = dim_date['date'].dt.strftime('%U')\n","dim_date['month_name'] = dim_date['date'].dt.strftime('%B')\n","dim_date['day_name'] = dim_date['date'].dt.strftime('%A')\n","dim_date['timestamp_isoformat'] = dim_date['date'].apply(lambda x: x.isoformat())\n","\n","#Add to tables\n","tables.append([dim_date,\"dim_date\"])\n","\n","#Show\n","#print(dim_date.shape)\n","#print(dim_date.info())\n","#print(dim_date.head())\n","dim_date.head()"]},{"cell_type":"markdown","id":"966df06b","metadata":{},"source":["# Dim Industry"]},{"cell_type":"code","execution_count":24,"id":"d260522f","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2022 NAICS US Code</th>\n","      <th>2022 NAICS US Title</th>\n","      <th>industry_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111</td>\n","      <td>Crop Production</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1111</td>\n","      <td>Oilseed and Grain Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11111</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>111110</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2120</th>\n","      <td>9281</td>\n","      <td>National Security and International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2121</th>\n","      <td>92811</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2122</th>\n","      <td>928110</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2123</th>\n","      <td>92812</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>928120</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2125 rows × 3 columns</p>\n","</div>"],"text/plain":["     2022 NAICS US Code                           2022 NAICS US Title  \\\n","0                    11    Agriculture, Forestry, Fishing and Hunting   \n","1                   111                               Crop Production   \n","2                  1111                     Oilseed and Grain Farming   \n","3                 11111                               Soybean Farming   \n","4                111110                               Soybean Farming   \n","...                 ...                                           ...   \n","2120               9281  National Security and International Affairs    \n","2121              92811                            National Security    \n","2122             928110                            National Security    \n","2123              92812                        International Affairs    \n","2124             928120                        International Affairs    \n","\n","                                   industry_type  \n","0     Agriculture, Forestry, Fishing and Hunting  \n","1     Agriculture, Forestry, Fishing and Hunting  \n","2     Agriculture, Forestry, Fishing and Hunting  \n","3     Agriculture, Forestry, Fishing and Hunting  \n","4     Agriculture, Forestry, Fishing and Hunting  \n","...                                          ...  \n","2120                       Public Administration  \n","2121                       Public Administration  \n","2122                       Public Administration  \n","2123                       Public Administration  \n","2124                       Public Administration  \n","\n","[2125 rows x 3 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["naics_df"]},{"cell_type":"code","execution_count":25,"id":"0908cb5e","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>NAICS_code</th>\n","      <th>industry_name</th>\n","      <th>industry_type</th>\n","      <th>industry_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111</td>\n","      <td>Crop Production</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1111</td>\n","      <td>Oilseed and Grain Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11111</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>111110</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  NAICS_code                               industry_name  \\\n","0         11  Agriculture, Forestry, Fishing and Hunting   \n","1        111                             Crop Production   \n","2       1111                   Oilseed and Grain Farming   \n","3      11111                             Soybean Farming   \n","4     111110                             Soybean Farming   \n","\n","                                industry_type  industry_id  \n","0  Agriculture, Forestry, Fishing and Hunting            1  \n","1  Agriculture, Forestry, Fishing and Hunting            2  \n","2  Agriculture, Forestry, Fishing and Hunting            3  \n","3  Agriculture, Forestry, Fishing and Hunting            4  \n","4  Agriculture, Forestry, Fishing and Hunting            5  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["#Create Dim\n","dim_industry = pd.DataFrame()\n","dim_industry['NAICS_code'] = naics_df['2022 NAICS US Code']\n","dim_industry['industry_name'] = naics_df['2022 NAICS US Title']\n","dim_industry['industry_type'] = naics_df['industry_type']\n","\n","#Add unique ID\n","dim_industry['industry_id'] = pd.factorize(dim_industry['NAICS_code'])[0] + 1\n","\n","#Add to tables\n","tables.append([dim_industry,\"dim_industry\"])\n","\n","#Show\n","dim_industry.head()"]},{"cell_type":"markdown","id":"c3ff1781","metadata":{},"source":["# Dim Census Location\n"]},{"cell_type":"code","execution_count":26,"id":"4018470f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#Create Dim\n","dim_census_location = ppp_df.select('ProjectCity','ProjectCountyName', \n","                                    'ProjectState', 'ProjectZip','CD')\n","dim_cen_count_BEFORE = dim_census_location.count()"]},{"cell_type":"code","execution_count":27,"id":"b44e345f","metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n","Transforming PySpark DataFrame...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Completed transforming PySpark DataFrame.\n","+-----------------+-------------------+-------------+-----------+-----+------------------+\n","|     project_city|project_county_name|project_state|project_zip|   cd|census_location_id|\n","+-----------------+-------------------+-------------+-----------+-----+------------------+\n","|Peachtree Corners|           GWINNETT|           GA| 30092-3536|GA-07|                 0|\n","|      STOCKBRIDGE|              HENRY|           GA| 30281-7432|GA-13|                 1|\n","|          ATLANTA|             FULTON|           GA| 30308-1078|GA-05|                 2|\n","|          ROSWELL|             FULTON|           GA| 30075-3027|GA-06|                 3|\n","|         Valdosta|            LOWNDES|           GA| 31602-0001|GA-08|                 4|\n","|           ALBANY|          DOUGHERTY|           GA| 31707-3879|GA-02|                 5|\n","|      GAINESVILLE|               HALL|           GA| 30501-3715|GA-09|                 6|\n","|          Atlanta|             FULTON|           GA| 30312-1976|GA-05|                 7|\n","|        BRUNSWICK|              GLYNN|           GA| 31520-2944|GA-01|                 8|\n","|           Canton|           CHEROKEE|           GA| 30114-6587|GA-11|                 9|\n","|        MCDONOUGH|              HENRY|           GA| 30253-0001|GA-10|                10|\n","|           ATHENS|             CLARKE|           GA| 30607-1000|GA-10|                11|\n","|         Norcross|           GWINNETT|           GA| 30093-0001|GA-07|                12|\n","|           POOLER|            CHATHAM|           GA| 31322-4016|GA-01|                13|\n","|         Marietta|               COBB|           GA| 30062-8828|GA-06|                14|\n","|          ATLANTA|             FULTON|           GA| 30306-3728|GA-05|                15|\n","|          ROSWELL|             FULTON|           GA| 30075-2506|GA-06|                16|\n","|          JACKSON|              BUTTS|           GA| 30233-4823|GA-10|                17|\n","|         MARIETTA|               COBB|           GA| 30062-8828|GA-06|                18|\n","|          Atlanta|             FULTON|           GA| 30350-4212|GA-06|                19|\n","+-----------------+-------------------+-------------+-----------+-----+------------------+\n","only showing top 20 rows\n","\n"]}],"source":["#Fix Names\n","dim_census_location = dim_census_location.withColumnRenamed(\"CD\",\"cd\")\n","dim_census_location = df_to_snake_case(dim_census_location)\n","\n","#Add unique ID\n","dim_census_location = create_ids(dim_census_location, \"census_location_id\")\n","\n","#Add to tables\n","tables.append([dim_census_location,\"dim_census_location\"])\n","\n","#Show\n","dim_census_location.show()"]},{"cell_type":"code","execution_count":28,"id":"c15f3eb3","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 19:===================================================>    (11 + 1) / 12]\r"]},{"name":"stdout","output_type":"stream","text":["Records in dim_census_location BEFORE: 10406068\n","Records in dim_census_location AFTER: 10406068\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["#Count\n","dim_cen_count_AFTER = dim_census_location.count()\n","print(\"Records in dim_census_location BEFORE: \"+str(dim_cen_count_BEFORE))\n","print(\"Records in dim_census_location AFTER: \"+str(dim_cen_count_AFTER))"]},{"cell_type":"markdown","id":"38a559a6","metadata":{},"source":["# Facts GDP"]},{"cell_type":"code","execution_count":29,"id":"3bb2fc3c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming Pandas DataFrame...\n","Completed transforming Pandas DataFrame.\n"]}],"source":["#Create facts\n","facts_gdp = gdp_df\n","\n","#Fix names\n","facts_gdp = df_to_snake_case(facts_gdp)\n","facts_gdp.rename(columns={'geo_f_i_p_s':'geofips'}, inplace=True)\n","\n","#Drop unnecessary columns\n","facts_gdp.drop('industry_classification',axis=1,inplace=True)"]},{"cell_type":"code","execution_count":31,"id":"47c4142e","metadata":{},"outputs":[],"source":["# Convert columns 2017-2022 to float\n","columns_to_convert = ['2017', '2018', '2019', '2020', '2021', '2022']\n","\n","# Convert columns to float while replacing invalid entries with NaN\n","facts_gdp[columns_to_convert] = facts_gdp[columns_to_convert].apply(pd.to_numeric, errors='coerce')"]},{"cell_type":"code","execution_count":32,"id":"76130016","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>geofips</th>\n","      <th>geo_name</th>\n","      <th>region</th>\n","      <th>table_name</th>\n","      <th>line_code</th>\n","      <th>description</th>\n","      <th>unit</th>\n","      <th>2017</th>\n","      <th>2018</th>\n","      <th>2019</th>\n","      <th>2020</th>\n","      <th>2021</th>\n","      <th>2022</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>2.166155e+08</td>\n","      <td>2.208088e+08</td>\n","      <td>2.249446e+08</td>\n","      <td>2.220814e+08</td>\n","      <td>2.318926e+08</td>\n","      <td>2.358073e+08</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>1.000000e+02</td>\n","      <td>1.019360e+02</td>\n","      <td>1.038450e+02</td>\n","      <td>1.025230e+02</td>\n","      <td>1.070530e+02</td>\n","      <td>1.088600e+02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>2.166155e+08</td>\n","      <td>2.262638e+08</td>\n","      <td>2.345264e+08</td>\n","      <td>2.351183e+08</td>\n","      <td>2.579865e+08</td>\n","      <td>2.815690e+08</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1001</td>\n","      <td>Autauga, AL</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>1.762558e+06</td>\n","      <td>1.787534e+06</td>\n","      <td>1.730861e+06</td>\n","      <td>1.722438e+06</td>\n","      <td>1.727818e+06</td>\n","      <td>1.929264e+06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1001</td>\n","      <td>Autauga, AL</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>1.000000e+02</td>\n","      <td>1.014170e+02</td>\n","      <td>9.820200e+01</td>\n","      <td>9.772400e+01</td>\n","      <td>9.802900e+01</td>\n","      <td>1.094580e+02</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9526</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>1.000000e+02</td>\n","      <td>1.045590e+02</td>\n","      <td>1.095520e+02</td>\n","      <td>1.093290e+02</td>\n","      <td>1.166610e+02</td>\n","      <td>1.193240e+02</td>\n","    </tr>\n","    <tr>\n","      <th>9527</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>6.813101e+08</td>\n","      <td>7.305677e+08</td>\n","      <td>7.762811e+08</td>\n","      <td>7.812724e+08</td>\n","      <td>8.801425e+08</td>\n","      <td>9.746826e+08</td>\n","    </tr>\n","    <tr>\n","      <th>9528</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>3.797440e+09</td>\n","      <td>3.956948e+09</td>\n","      <td>4.108526e+09</td>\n","      <td>4.048650e+09</td>\n","      <td>4.342903e+09</td>\n","      <td>4.385658e+09</td>\n","    </tr>\n","    <tr>\n","      <th>9529</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>1.000000e+02</td>\n","      <td>1.042000e+02</td>\n","      <td>1.081920e+02</td>\n","      <td>1.066150e+02</td>\n","      <td>1.143640e+02</td>\n","      <td>1.154900e+02</td>\n","    </tr>\n","    <tr>\n","      <th>9530</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>3.797440e+09</td>\n","      <td>4.026579e+09</td>\n","      <td>4.252235e+09</td>\n","      <td>4.254017e+09</td>\n","      <td>4.732878e+09</td>\n","      <td>5.066774e+09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9531 rows × 13 columns</p>\n","</div>"],"text/plain":["      geofips        geo_name  region table_name  line_code  \\\n","0        1000         Alabama     5.0     CAGDP1          1   \n","1        1000         Alabama     5.0     CAGDP1          2   \n","2        1000         Alabama     5.0     CAGDP1          3   \n","3        1001     Autauga, AL     5.0     CAGDP1          1   \n","4        1001     Autauga, AL     5.0     CAGDP1          2   \n","...       ...             ...     ...        ...        ...   \n","9526    97000  Rocky Mountain     7.0     CAGDP1          2   \n","9527    97000  Rocky Mountain     7.0     CAGDP1          3   \n","9528    98000        Far West     8.0     CAGDP1          1   \n","9529    98000        Far West     8.0     CAGDP1          2   \n","9530    98000        Far West     8.0     CAGDP1          3   \n","\n","                                            description  \\\n","0         Real GDP (thousands of chained 2017 dollars)    \n","1             Chain-type quantity indexes for real GDP    \n","2     Current-dollar GDP (thousands of current dolla...   \n","3         Real GDP (thousands of chained 2017 dollars)    \n","4             Chain-type quantity indexes for real GDP    \n","...                                                 ...   \n","9526          Chain-type quantity indexes for real GDP    \n","9527  Current-dollar GDP (thousands of current dolla...   \n","9528      Real GDP (thousands of chained 2017 dollars)    \n","9529          Chain-type quantity indexes for real GDP    \n","9530  Current-dollar GDP (thousands of current dolla...   \n","\n","                                   unit          2017          2018  \\\n","0     Thousands of chained 2017 dollars  2.166155e+08  2.208088e+08   \n","1                        Quantity index  1.000000e+02  1.019360e+02   \n","2                  Thousands of dollars  2.166155e+08  2.262638e+08   \n","3     Thousands of chained 2017 dollars  1.762558e+06  1.787534e+06   \n","4                        Quantity index  1.000000e+02  1.014170e+02   \n","...                                 ...           ...           ...   \n","9526                     Quantity index  1.000000e+02  1.045590e+02   \n","9527               Thousands of dollars  6.813101e+08  7.305677e+08   \n","9528  Thousands of chained 2017 dollars  3.797440e+09  3.956948e+09   \n","9529                     Quantity index  1.000000e+02  1.042000e+02   \n","9530               Thousands of dollars  3.797440e+09  4.026579e+09   \n","\n","              2019          2020          2021          2022  \n","0     2.249446e+08  2.220814e+08  2.318926e+08  2.358073e+08  \n","1     1.038450e+02  1.025230e+02  1.070530e+02  1.088600e+02  \n","2     2.345264e+08  2.351183e+08  2.579865e+08  2.815690e+08  \n","3     1.730861e+06  1.722438e+06  1.727818e+06  1.929264e+06  \n","4     9.820200e+01  9.772400e+01  9.802900e+01  1.094580e+02  \n","...            ...           ...           ...           ...  \n","9526  1.095520e+02  1.093290e+02  1.166610e+02  1.193240e+02  \n","9527  7.762811e+08  7.812724e+08  8.801425e+08  9.746826e+08  \n","9528  4.108526e+09  4.048650e+09  4.342903e+09  4.385658e+09  \n","9529  1.081920e+02  1.066150e+02  1.143640e+02  1.154900e+02  \n","9530  4.252235e+09  4.254017e+09  4.732878e+09  5.066774e+09  \n","\n","[9531 rows x 13 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["#Show\n","facts_gdp"]},{"cell_type":"markdown","id":"6ba1a5a9","metadata":{},"source":["#### Now we will begin the process of connecting facts_gdp with dim_census_location"]},{"cell_type":"code","execution_count":33,"id":"8662fcbd","metadata":{},"outputs":[],"source":["# Start by converting facts_gdp to a spark df so we can work on it better\n","facts_gdp_spark = spark.createDataFrame(facts_gdp)"]},{"cell_type":"code","execution_count":34,"id":"331699e3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------+-----------+------------------+\n","|    geo_name|county_name|state_abbreviation|\n","+------------+-----------+------------------+\n","|   Clark, ID|      Clark|                ID|\n","|    Elko, NV|       Elko|                NV|\n","| Volusia, FL|    Volusia|                FL|\n","|   Adams, IN|      Adams|                IN|\n","| Loudoun, VA|    Loudoun|                VA|\n","|  Queens, NY|     Queens|                NY|\n","|Garfield, OK|   Garfield|                OK|\n","|    Ware, GA|       Ware|                GA|\n","|      Hawaii|     Hawaii|              NULL|\n","|    Boyd, KY|       Boyd|                KY|\n","+------------+-----------+------------------+\n","\n"]}],"source":["#Next, we split the geo_name column so we can easily get the county name and state abbriviation\n","facts_gdp_spark = facts_gdp_spark.withColumn(\"county_name\", split(col(\"geo_name\"), \",\")[0])\n","facts_gdp_spark = facts_gdp_spark.withColumn(\"state_abbreviation\", trim(split(col(\"geo_name\"), \",\")[1]))\n","facts_gdp_spark.select(\"geo_name\",\"county_name\",\"state_abbreviation\").orderBy(rand()).limit(10).show()"]},{"cell_type":"code","execution_count":35,"id":"6fe8d280","metadata":{},"outputs":[],"source":["# quickly get the count of rows before we set the df to the joined df. This is for debugging purposes\n","facts_gpd_spark_before_count = facts_gdp_spark.count()"]},{"cell_type":"code","execution_count":36,"id":"b34b3337","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----------+------------------+-------------------+-------------+-----------+-----+------------------+\n","|county_name|state_abbreviation|project_county_name|project_state|project_zip|   cd|census_location_id|\n","+-----------+------------------+-------------------+-------------+-----------+-----+------------------+\n","|      Anoka|                MN|              ANOKA|           MN| 55448-1160|MN-03|           1790754|\n","|    Volusia|                FL|            VOLUSIA|           FL| 32119-2827|FL-06|           8731570|\n","|     Marion|                IN|             MARION|           IN| 46226-0001|IN-07|           3735839|\n","|       Knox|                TN|               KNOX|           TN| 37932-1000|TN-02|           2146209|\n","|  Craighead|                AR|          CRAIGHEAD|           AR| 72417-0564|AR-01|           4343237|\n","|     Benton|                IA|             BENTON|           IA| 52315-4702|IA-02|           2983080|\n","|    Lubbock|                TX|            LUBBOCK|           TX| 79424-6698|TX-19|           3950389|\n","|  Middlesex|                MA|          MIDDLESEX|           MA| 01801-7242|MA-05|            126688|\n","|       Will|                IL|               WILL|           IL| 60448-9345|IL-01|           8560578|\n","|     Benton|                IA|             BENTON|           IA| 52213-9266|IA-02|           2948176|\n","+-----------+------------------+-------------------+-------------+-----------+-----+------------------+\n","\n"]}],"source":["# Clean the state abbreviations (e.g., removing any \"*\" characters)\n","df1_cleaned = facts_gdp_spark.withColumn(\"state_abbreviation\", regexp_replace(\"state_abbreviation\", r\"\\*\", \"\"))\n","df2_cleaned = dim_census_location.withColumn(\"project_state\", regexp_replace(\"project_state\", r\"\\*\", \"\"))\n","\n","# Make join condition (which is also case insensitive)\n","join_condition = (lower(col(\"df1.county_name\")) == lower(col(\"df2.project_county_name\"))) & \\\n","                 (lower(col(\"df1.state_abbreviation\")) == lower(col(\"df2.project_state\")))\n","\n","# Perform the join\n","joined_df = df1_cleaned.alias(\"df1\").join(df2_cleaned.alias(\"df2\"), on=join_condition, how=\"left\")\n","\n","# Show the result\n","joined_df.select(\"county_name\",\"state_abbreviation\",\"project_county_name\",\n","                 \"project_state\",\"project_zip\",\"cd\", \"census_location_id\").orderBy(rand()).limit(10).show()"]},{"cell_type":"code","execution_count":37,"id":"1494d9c8","metadata":{},"outputs":[],"source":["# Set facts_gdp_spark to new joined_df, then delete joined df\n","facts_gdp_spark = joined_df\n","del joined_df"]},{"cell_type":"code","execution_count":38,"id":"973ae9e6","metadata":{},"outputs":[],"source":["# Finally, we drop columns thats not needed\n","facts_gdp_spark.columns\n","facts_gdp_spark = facts_gdp_spark.drop(\"county_name\",\"state_abbreviation\", \"project_county_name\",\n","                                      \"project_state\", \"project_zip\",\"cd\")"]},{"cell_type":"code","execution_count":39,"id":"3c91298e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 40:===================================================>    (11 + 1) / 12]\r"]},{"name":"stdout","output_type":"stream","text":["Fact_GPD_SPARK_BEFORE: 9531\n","Fact_GPD_SPARK_AFTER: 29915703\n","Fact_GPD_PANDAS: 9531\n","DIM_Census_Location: 10406068\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# See how much we changed facts_gpd\n","facts_gpd_spark_after_count = facts_gdp_spark.count()\n","facts_gpd_pandas_count =len(facts_gdp)\n","dim_census_location_count = dim_census_location.count()\n","\n","print(\"Fact_GPD_SPARK_BEFORE: \"+str(facts_gpd_spark_before_count))\n","print(\"Fact_GPD_SPARK_AFTER: \"+str(facts_gpd_spark_after_count))\n","print(\"Fact_GPD_PANDAS: \"+str(facts_gpd_pandas_count))\n","print(\"DIM_Census_Location: \"+str(dim_census_location_count))"]},{"cell_type":"code","execution_count":40,"id":"4ffd43a3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting handyspark\n","  Downloading handyspark-0.2.2a1-py2.py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: pyspark in /usr/lib/spark/python (from handyspark) (3.5.1)\n","Requirement already satisfied: matplotlib in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (3.8.4)\n","Requirement already satisfied: numpy in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (1.26.4)\n","Requirement already satisfied: scipy in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (1.11.4)\n","Requirement already satisfied: seaborn in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (0.13.2)\n","Requirement already satisfied: pandas in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (2.1.4)\n","Requirement already satisfied: scikit-learn in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (1.3.2)\n","Collecting findspark (from handyspark)\n","  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n","Requirement already satisfied: pyarrow in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (14.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (23.1)\n","Requirement already satisfied: pillow>=8 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (2.9.0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->handyspark) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->handyspark) (2024.2)\n","Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pyspark->handyspark) (0.10.9.7)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from scikit-learn->handyspark) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from scikit-learn->handyspark) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->handyspark) (1.16.0)\n","Downloading handyspark-0.2.2a1-py2.py3-none-any.whl (39 kB)\n","Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n","Installing collected packages: findspark, handyspark\n","Successfully installed findspark-2.0.1 handyspark-0.2.2a1\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/spark/python/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n","  warnings.warn(\n","/usr/lib/spark/python/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n","  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n","                                                                                \r"]},{"data":{"text/plain":["geofips                 0\n","geo_name                0\n","region                  0\n","table_name              0\n","line_code               0\n","description             0\n","unit                    0\n","2017                    0\n","2018                    0\n","2019                    0\n","2020                    0\n","2021                    0\n","2022                    0\n","project_city          513\n","census_location_id    513\n","Name: missing, dtype: int64"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# Check how much of facts_gdp is null after join\n","!pip install handyspark\n","import numpy as np\n","np.bool = np.bool_\n","from handyspark import *\n","hsdf = HandyFrame(facts_gdp_spark)\n","hsdf.isnull()"]},{"cell_type":"code","execution_count":41,"id":"f66bd6bc","metadata":{},"outputs":[],"source":["# Add unique ID\n","facts_gdp_spark = facts_gdp_spark.withColumn(\"facts_gdp_id\", monotonically_increasing_id()+1)\n","\n","# Add to tables\n","tables.append([facts_gdp_spark,\"facts_gdp\"])"]},{"cell_type":"markdown","id":"b34378d0","metadata":{},"source":["# Facts PPP Loans"]},{"cell_type":"code","execution_count":42,"id":"da70ed83","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n"]},{"data":{"text/plain":["['sba_guaranty_percentage',\n"," 'initial_approval_amount',\n"," 'current_approval_amount',\n"," 'undisbursed_amount',\n"," 'forgiveness_amount',\n"," 'loan_number',\n"," 'loan_status',\n"," 'term',\n"," 'rural_urban_indicator',\n"," 'hubzone_indicator',\n"," 'lmi_indicator',\n"," 'jobs_reported',\n"," 'sba_office_code',\n"," 'servicing_lender_location_id',\n"," 'originating_lender_location_id',\n"," 'processing_method',\n"," 'date_approved_id',\n"," 'loan_status_date_id',\n"," 'forgiveness_date_id',\n"," 'borrower_id',\n"," 'NAICS_code_industry_id',\n"," 'fact_ppp_id']"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["# Small function to convert date columns to date_id to connect to dim_date table.\n","def date_to_id(df, column_name):\n","    df = df.withColumn(column_name+\"_id\", date_format(column_name, \"yyyyMMdd\").cast(\"int\"))\n","    df = df.drop(column_name)\n","    return df\n","\n","\n","# Create facts\n","facts_PPP_loans = ppp_df.select(\"SBAGuarantyPercentage\",\"InitialApprovalAmount\",\"CurrentApprovalAmount\",\n","                               \"UndisbursedAmount\",\"ForgivenessAmount\",\"LoanNumber\",\"LoanStatus\",\"Term\",\n","                               \"RuralUrbanIndicator\",\"HubzoneIndicator\",\"LMIIndicator\",\"JobsReported\",\n","                                \"date_approved\", \"loan_status_date\",\"forgiveness_date\",\n","                               \"SBAOfficeCode\",\"ServicingLenderLocationID\",\"OriginatingLenderLocationID\",\n","                               \"ProcessingMethod\",\"NAICSCode\")\n","\n","# Convert date cols to date_ids so we can connect it to the dim date if needed\n","facts_PPP_loans = date_to_id(facts_PPP_loans,\"date_approved\")\n","facts_PPP_loans = date_to_id(facts_PPP_loans,\"loan_status_date\")\n","facts_PPP_loans = date_to_id(facts_PPP_loans,\"forgiveness_date\")\n","\n","\n","# Fix names\n","facts_PPP_loans = df_to_snake_case(facts_PPP_loans)\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"s_b_a_office_code\",\"sba_office_code\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"s_b_a_guaranty_percentage\",\"sba_guaranty_percentage\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"servicing_lender_location_i_d\",\"servicing_lender_location_id\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"originating_lender_location_i_d\",\"originating_lender_location_id\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"l_m_i_indicator\",\"lmi_indicator\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"n_a_i_c_s_code\",\"NAICS_code\")\n","\n","\n","# Add foreign IDs\n","facts_PPP_loans = facts_PPP_loans.withColumn(\"borrower_id\", col(\"loan_number\")) \n","\n","# Adding the industry_id as a foreign key.\n","#- 1st, join facts dataframe with dim_industry on the naics code\n","facts_PPP_loans = facts_PPP_loans.join(spark.createDataFrame(dim_industry), \n","                                       on=\"NAICS_code\", how=\"inner\")\n","#- 2nd, drop all columns from dim_industry beside the industry id\n","facts_PPP_loans = facts_PPP_loans.drop(\"NAICS_code\",\"industry_type\",\"industry_name\")\n","\n","#- 3rd, rename industry_id to NAICS_code_industry_id\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"industry_id\",\"NAICS_code_industry_id\")\n","\n","# Add unique IDs\n","facts_PPP_loans = facts_PPP_loans.withColumn(\"fact_ppp_id\", monotonically_increasing_id()+1)\n","\n","# Add to tables\n","tables.append([facts_PPP_loans,\"facts_PPP_loans\"])\n","\n","# Show\n","facts_PPP_loans.columns"]},{"cell_type":"markdown","id":"ca09ff1e","metadata":{},"source":["# Functions for saving\n","\n","Note: All functions assume we have global variable \"bucket\" that contains the name of the bucket we are working with"]},{"cell_type":"code","execution_count":43,"id":"f4ca4ca2","metadata":{},"outputs":[],"source":["def check_folder_exists(folder_name):\n","    \n","    # Grab the bucket\n","    client = storage.Client()\n","    bucket_ = client.get_bucket(bucket)\n","    \n","    # List objects in the bucket with the folder prefix\n","    blobs = bucket_.list_blobs(prefix=folder_name + '/')\n","    \n","    # Check if any blob exists under this folder\n","    for blob in blobs:\n","        if blob.name.startswith(folder_name + '/'):\n","            print(f\"Folder '{folder_name}' exists in bucket '{bucket}'.\")\n","            return True\n","    \n","    print(f\"Folder '{folder_name}' does not exist in bucket '{bucket}'.\")\n","    return False"]},{"cell_type":"code","execution_count":44,"id":"92f23f8d","metadata":{},"outputs":[],"source":["def create_folder(path, name):\n","    \n","    if check_folder_exists(name): \n","        print(path+name+'/'+' already exists. Abandoning folder creation')\n","        return\n","    \n","    # Initialize the GCS client\n","    client = storage.Client()\n","\n","    # Get the bucket\n","    _bucket = client.get_bucket(bucket)\n","\n","    # Define the folder path\n","    folder_path = path+name+'/'\n","\n","    # Create a dummy file in the folder (this will simulate the folder in GCS)\n","    # The 'blob' will not be a real file, but will create the \"folder\"\n","    blob = _bucket.blob(folder_path + 'placeholder.txt')  # You can name it anything, like 'placeholder.txt'\n","\n","    # Upload an empty string or any content to simulate the folder creation\n","    blob.upload_from_string('')\n","\n","    print(f\"Folder '{folder_path}' created successfully in the bucket '{bucket}'\")"]},{"cell_type":"code","execution_count":45,"id":"fa75ff70","metadata":{},"outputs":[],"source":["def delete_files_named(name_of_file_to_delete):\n","    # Initialize a client\n","    client = storage.Client()\n","\n","    # Specify the bucket name\n","    _bucket = client.bucket(bucket)\n","\n","    # List and delete all files named \"placeholder.txt\"\n","    blobs = _bucket.list_blobs()\n","\n","    count_deleted = 0\n","    for blob in blobs:\n","        if blob.name.endswith(name_of_file_to_delete):\n","            blob.delete()\n","            print(f\"Deleted: {blob.name}\")\n","            count_deleted += 1\n","            \n","    \n","    print(f\"Deletion of all '{name_of_file_to_delete}' files is complete. Total deleted: \"+str(count_deleted))"]},{"cell_type":"code","execution_count":46,"id":"1eeb42b6","metadata":{},"outputs":[],"source":["def save_df(df,name,save_as=\"parquet\",gcs_path=None):\n","\n","    #we must define the bucket variable at the start of the script, before calling this function.\n","    \n","    # Define the GCS path for saving the file\n","    if gcs_path == None:\n","        gcs_path = 'gs://'+bucket+'/dim_ready/'+name+'/'+name+'.'+save_as\n","    \n","    \n","    \n","    print(f\"Creating '{name}' folder...\")\n","    create_folder('dim_ready/',name)\n","    delete_files_named(\"placeholder.txt\")\n","    \n","    print(\"Beginning saving process...\")\n","    flag = 0 # this var will let us know is there as been an error\n","    \n","    #Saves Pandas dataframe\n","    if isinstance(df, pd.DataFrame):\n","        # Initialize GCS file system\n","        fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","\n","        # Save DataFrame to the \"cleaned\" folder in the GCS bucket\n","        with fs.open(gcs_path, 'w') as f:\n","            if save_as == \"csv\":\n","                df.to_csv(f, index=False)\n","            else:\n","                print(\"INVALD FILE FORMAT. TRY [csv]\")\n","                flag+=1\n","        \n","        if flag == 0:\n","            print(\"Successfully saved \"+name+ \"!\")\n","    \n","    #Saves PySpark dataframe\n","    elif isinstance(df, PySparkDataFrame):\n","        if save_as == \"parquet\":\n","            df.write.parquet(gcs_path,mode=\"overwrite\")\n","        elif save_as == \"csv\":\n","            df.write.csv(gcs_path,mode=\"overwrite\")\n","        elif save_as == \"avro\":\n","            df.write.format(\"avro\").save(gcs_path,mode=\"overwrite\")\n","        else:\n","            print(\"INVALD FILE FORMAT. TRY [csv] or [parquet] or [avro]\")\n","            flag+=1\n","        \n","        if flag == 0:\n","            print(\"Successfully saved \"+name+ \"!\")\n","        \n","    #No valid dataframe found\n","    else:\n","        print(\"ERROR: INVALID DATAFRAME - NO PROCEDURE APPLIED\")"]},{"cell_type":"code","execution_count":47,"id":"ed33de49","metadata":{},"outputs":[],"source":["#this function accepts a list of tables, that each contain 2 elements, the table itself, and the name of the table.\n","#Example, table[0] = [df_1,\"df_1_name\"], table[1][0] = df_2, table[3][1] = \"df_4_name\"\n","def save_list_of_df(list_of_tables,pandas_save=\"csv\",pyspark_save=\"parquet\"):\n","    for table in list_of_tables:\n","        if isinstance(table[0], pd.DataFrame):\n","            save_df(table[0],table[1],save_as=pandas_save)\n","        elif isinstance(table[0], PySparkDataFrame):\n","            save_df(table[0],table[1],save_as=pyspark_save)"]},{"cell_type":"markdown","id":"9873c12d","metadata":{},"source":["# Saving Dims and Facts"]},{"cell_type":"code","execution_count":48,"id":"22534c1e","metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating 'dim_borrower' folder...\n","Folder 'dim_borrower' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_borrower/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_borrower/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved dim_borrower!\n","Creating 'dim_SBA_office' folder...\n","Folder 'dim_SBA_office' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_SBA_office/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_SBA_office/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n","Successfully saved dim_SBA_office!\n","Creating 'dim_processing_method' folder...\n","Folder 'dim_processing_method' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_processing_method/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_processing_method/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n","Successfully saved dim_processing_method!\n","Creating 'dim_originating_lender' folder...\n","Folder 'dim_originating_lender' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_originating_lender/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_originating_lender/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved dim_originating_lender!\n","Creating 'dim_servicing_lender' folder...\n","Folder 'dim_servicing_lender' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_servicing_lender/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_servicing_lender/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved dim_servicing_lender!\n","Creating 'dim_date' folder...\n","Folder 'dim_date' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_date/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_date/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n","Successfully saved dim_date!\n","Creating 'dim_industry' folder...\n","Folder 'dim_industry' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_industry/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_industry/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n","Successfully saved dim_industry!\n","Creating 'dim_census_location' folder...\n","Folder 'dim_census_location' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_census_location/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_census_location/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved dim_census_location!\n","Creating 'facts_gdp' folder...\n","Folder 'facts_gdp' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/facts_gdp/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/facts_gdp/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved facts_gdp!\n","Creating 'facts_PPP_loans' folder...\n","Folder 'facts_PPP_loans' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/facts_PPP_loans/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/facts_PPP_loans/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved facts_PPP_loans!\n"]}],"source":["#We will simply save all Pandas dataframes as CSV's and all PySpark ones as parquet\n","\n","ENABLE_SAVE = True #boolean to quickly turn on/off saving. Good to turn off saving when debugging.\n","\n","if ENABLE_SAVE:\n","    save_list_of_df(tables)"]},{"cell_type":"code","execution_count":49,"id":"641593a0","metadata":{},"outputs":[],"source":["# ISSUES\n","\n","# There are null values in industry type when joining it on NAICS code. That is because the naics code wasnt found\n","# inside the dim_industry table. So no value was able to come of it. \n","\n","\n","# DIFFERENCES BETWEEN THIS AND CURRENT DIM MODEL\n","\n","# PPP Fact Table currently has \"term\" and \"term_date_id\" in the model. However...\n","# Script wise, I did not include term_date_id, and left term as is since it doesnt correspond to a date."]},{"cell_type":"code","execution_count":null,"id":"f3f5ed37","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}