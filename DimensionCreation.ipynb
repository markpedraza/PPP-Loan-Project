{"cells":[{"cell_type":"code","execution_count":1,"id":"5b505ed8","metadata":{"scrolled":true},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-20241208a-m.us-central1-f.c.cis4400-group-project-ppp.internal:42407\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fc445e58c50>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"markdown","id":"db9a4d22","metadata":{},"source":["# Initial Setup (Install and import necessary packages)"]},{"cell_type":"code","execution_count":2,"id":"217f5e8e","metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gcsfs in /opt/conda/miniconda3/lib/python3.11/site-packages (2023.12.2.post1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (3.10.10)\n","Requirement already satisfied: decorator>4.1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (5.1.1)\n","Requirement already satisfied: fsspec==2023.12.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2023.12.2)\n","Requirement already satisfied: google-auth>=1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2.35.0)\n","Requirement already satisfied: google-auth-oauthlib in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (1.1.0)\n","Requirement already satisfied: google-cloud-storage in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2.13.0)\n","Requirement already satisfied: requests in /opt/conda/miniconda3/lib/python3.11/site-packages (from gcsfs) (2.31.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.16.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.21.0)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.4.1)\n","Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.7.2)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (1.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->gcsfs) (2024.8.30)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.65.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (4.24.4)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.25.0)\n","Requirement already satisfied: cffi>=1.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from google-crc32c<2.0dev,>=1.0->google-cloud-storage->gcsfs) (1.16.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n","Requirement already satisfied: propcache>=0.2.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.2.0)\n","Requirement already satisfied: pycparser in /opt/conda/miniconda3/lib/python3.11/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-cloud-storage->gcsfs) (2.21)\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0mRequirement already satisfied: openpyxl in /opt/conda/miniconda3/lib/python3.11/site-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /opt/conda/miniconda3/lib/python3.11/site-packages (from openpyxl) (2.0.0)\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install gcsfs\n","!pip install openpyxl"]},{"cell_type":"code","execution_count":3,"id":"42cc1fcc","metadata":{},"outputs":[],"source":["import pandas as pd\n","import gcsfs\n","import calendar\n","from google.cloud import storage\n","from google.cloud.exceptions import NotFound\n","from pyspark.sql import Row\n","from pyspark.sql.functions import col, lower, instr, date_format, split, rand, regexp_replace, trim, max\n","from pyspark.sql.functions import monotonically_increasing_id # virtually the same as factorize() from pandas."]},{"cell_type":"code","execution_count":4,"id":"f7c74a1d","metadata":{},"outputs":[],"source":["# Define the bucket we will save to. Many areas will reference this variable later\n","bucket = \"ppp-loans-bucket\""]},{"cell_type":"markdown","id":"657493ba","metadata":{},"source":["# Read clean data into appropriate dataframes"]},{"cell_type":"code","execution_count":5,"id":"93acaa5e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["ppp_df = spark.read.parquet(\"gs://ppp-loans-bucket/cleaned/part-*\")#.sample(fraction=0.001,seed=42)"]},{"cell_type":"code","execution_count":6,"id":"7dd1f5fc","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["10406068"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["ppp_df.count()"]},{"cell_type":"code","execution_count":7,"id":"2cbf2fc0","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>GeoFIPS</th>\n","      <th>GeoName</th>\n","      <th>Region</th>\n","      <th>TableName</th>\n","      <th>LineCode</th>\n","      <th>IndustryClassification</th>\n","      <th>Description</th>\n","      <th>Unit</th>\n","      <th>2017</th>\n","      <th>2018</th>\n","      <th>2019</th>\n","      <th>2020</th>\n","      <th>2021</th>\n","      <th>2022</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>216615470</td>\n","      <td>220808767</td>\n","      <td>224944577</td>\n","      <td>222081439</td>\n","      <td>231892626</td>\n","      <td>235807320</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>101.936</td>\n","      <td>103.845</td>\n","      <td>102.523</td>\n","      <td>107.053</td>\n","      <td>108.86</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>216615470</td>\n","      <td>226263784</td>\n","      <td>234526408</td>\n","      <td>235118280</td>\n","      <td>257986516</td>\n","      <td>281569005</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1001</td>\n","      <td>Autauga, AL</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>1762558</td>\n","      <td>1787534</td>\n","      <td>1730861</td>\n","      <td>1722438</td>\n","      <td>1727818</td>\n","      <td>1929264</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1001</td>\n","      <td>Autauga, AL</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>101.417</td>\n","      <td>98.202</td>\n","      <td>97.724</td>\n","      <td>98.029</td>\n","      <td>109.458</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9526</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>104.559</td>\n","      <td>109.552</td>\n","      <td>109.329</td>\n","      <td>116.661</td>\n","      <td>119.324</td>\n","    </tr>\n","    <tr>\n","      <th>9527</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>681310123</td>\n","      <td>730567674</td>\n","      <td>776281078</td>\n","      <td>781272363</td>\n","      <td>880142487</td>\n","      <td>974682556</td>\n","    </tr>\n","    <tr>\n","      <th>9528</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>3797440495</td>\n","      <td>3956948041</td>\n","      <td>4108525822</td>\n","      <td>4048649569</td>\n","      <td>4342903004</td>\n","      <td>4385657757</td>\n","    </tr>\n","    <tr>\n","      <th>9529</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>100</td>\n","      <td>104.2</td>\n","      <td>108.192</td>\n","      <td>106.615</td>\n","      <td>114.364</td>\n","      <td>115.49</td>\n","    </tr>\n","    <tr>\n","      <th>9530</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>3797440495</td>\n","      <td>4026578971</td>\n","      <td>4252235190</td>\n","      <td>4254017130</td>\n","      <td>4732878464</td>\n","      <td>5066773749</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9531 rows × 14 columns</p>\n","</div>"],"text/plain":["      GeoFIPS         GeoName  Region TableName  LineCode  \\\n","0        1000         Alabama     5.0    CAGDP1         1   \n","1        1000         Alabama     5.0    CAGDP1         2   \n","2        1000         Alabama     5.0    CAGDP1         3   \n","3        1001     Autauga, AL     5.0    CAGDP1         1   \n","4        1001     Autauga, AL     5.0    CAGDP1         2   \n","...       ...             ...     ...       ...       ...   \n","9526    97000  Rocky Mountain     7.0    CAGDP1         2   \n","9527    97000  Rocky Mountain     7.0    CAGDP1         3   \n","9528    98000        Far West     8.0    CAGDP1         1   \n","9529    98000        Far West     8.0    CAGDP1         2   \n","9530    98000        Far West     8.0    CAGDP1         3   \n","\n","     IndustryClassification  \\\n","0                       ...   \n","1                       ...   \n","2                       ...   \n","3                       ...   \n","4                       ...   \n","...                     ...   \n","9526                    ...   \n","9527                    ...   \n","9528                    ...   \n","9529                    ...   \n","9530                    ...   \n","\n","                                            Description  \\\n","0         Real GDP (thousands of chained 2017 dollars)    \n","1             Chain-type quantity indexes for real GDP    \n","2     Current-dollar GDP (thousands of current dolla...   \n","3         Real GDP (thousands of chained 2017 dollars)    \n","4             Chain-type quantity indexes for real GDP    \n","...                                                 ...   \n","9526          Chain-type quantity indexes for real GDP    \n","9527  Current-dollar GDP (thousands of current dolla...   \n","9528      Real GDP (thousands of chained 2017 dollars)    \n","9529          Chain-type quantity indexes for real GDP    \n","9530  Current-dollar GDP (thousands of current dolla...   \n","\n","                                   Unit        2017        2018        2019  \\\n","0     Thousands of chained 2017 dollars   216615470   220808767   224944577   \n","1                        Quantity index         100     101.936     103.845   \n","2                  Thousands of dollars   216615470   226263784   234526408   \n","3     Thousands of chained 2017 dollars     1762558     1787534     1730861   \n","4                        Quantity index         100     101.417      98.202   \n","...                                 ...         ...         ...         ...   \n","9526                     Quantity index         100     104.559     109.552   \n","9527               Thousands of dollars   681310123   730567674   776281078   \n","9528  Thousands of chained 2017 dollars  3797440495  3956948041  4108525822   \n","9529                     Quantity index         100       104.2     108.192   \n","9530               Thousands of dollars  3797440495  4026578971  4252235190   \n","\n","            2020        2021        2022  \n","0      222081439   231892626   235807320  \n","1        102.523     107.053      108.86  \n","2      235118280   257986516   281569005  \n","3        1722438     1727818     1929264  \n","4         97.724      98.029     109.458  \n","...          ...         ...         ...  \n","9526     109.329     116.661     119.324  \n","9527   781272363   880142487   974682556  \n","9528  4048649569  4342903004  4385657757  \n","9529     106.615     114.364      115.49  \n","9530  4254017130  4732878464  5066773749  \n","\n","[9531 rows x 14 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","with fs.open(\"ppp-loans-bucket/cleaned/GDP.csv\") as f:\n","    gdp_df = pd.read_csv(f)\n","gdp_df"]},{"cell_type":"code","execution_count":8,"id":"233ba7fd","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2022 NAICS US Code</th>\n","      <th>2022 NAICS US Title</th>\n","      <th>industry_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111</td>\n","      <td>Crop Production</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1111</td>\n","      <td>Oilseed and Grain Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11111</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>111110</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2120</th>\n","      <td>9281</td>\n","      <td>National Security and International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2121</th>\n","      <td>92811</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2122</th>\n","      <td>928110</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2123</th>\n","      <td>92812</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>928120</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2125 rows × 3 columns</p>\n","</div>"],"text/plain":["     2022 NAICS US Code                           2022 NAICS US Title  \\\n","0                    11    Agriculture, Forestry, Fishing and Hunting   \n","1                   111                               Crop Production   \n","2                  1111                     Oilseed and Grain Farming   \n","3                 11111                               Soybean Farming   \n","4                111110                               Soybean Farming   \n","...                 ...                                           ...   \n","2120               9281  National Security and International Affairs    \n","2121              92811                            National Security    \n","2122             928110                            National Security    \n","2123              92812                        International Affairs    \n","2124             928120                        International Affairs    \n","\n","                                   industry_type  \n","0     Agriculture, Forestry, Fishing and Hunting  \n","1     Agriculture, Forestry, Fishing and Hunting  \n","2     Agriculture, Forestry, Fishing and Hunting  \n","3     Agriculture, Forestry, Fishing and Hunting  \n","4     Agriculture, Forestry, Fishing and Hunting  \n","...                                          ...  \n","2120                       Public Administration  \n","2121                       Public Administration  \n","2122                       Public Administration  \n","2123                       Public Administration  \n","2124                       Public Administration  \n","\n","[2125 rows x 3 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","with fs.open('ppp-loans-bucket/cleaned/NAICS.csv') as f:\n","    naics_df = pd.read_csv(f)\n","naics_df"]},{"cell_type":"markdown","id":"584f82a9","metadata":{},"source":["# Checking columns"]},{"cell_type":"code","execution_count":9,"id":"803494d1","metadata":{},"outputs":[{"data":{"text/plain":["['LoanNumber',\n"," 'DateApproved',\n"," 'SBAOfficeCode',\n"," 'ProcessingMethod',\n"," 'BorrowerName',\n"," 'BorrowerAddress',\n"," 'BorrowerCity',\n"," 'BorrowerState',\n"," 'BorrowerZip',\n"," 'LoanStatusDate',\n"," 'LoanStatus',\n"," 'Term',\n"," 'SBAGuarantyPercentage',\n"," 'InitialApprovalAmount',\n"," 'CurrentApprovalAmount',\n"," 'UndisbursedAmount',\n"," 'FranchiseName',\n"," 'ServicingLenderLocationID',\n"," 'ServicingLenderName',\n"," 'ServicingLenderAddress',\n"," 'ServicingLenderCity',\n"," 'ServicingLenderState',\n"," 'ServicingLenderZip',\n"," 'RuralUrbanIndicator',\n"," 'HubzoneIndicator',\n"," 'LMIIndicator',\n"," 'BusinessAgeDescription',\n"," 'ProjectCity',\n"," 'ProjectCountyName',\n"," 'ProjectState',\n"," 'ProjectZip',\n"," 'CD',\n"," 'JobsReported',\n"," 'NAICSCode',\n"," 'Race',\n"," 'Ethnicity',\n"," 'PAYROLL_PROCEED',\n"," 'BusinessType',\n"," 'OriginatingLenderLocationID',\n"," 'OriginatingLender',\n"," 'OriginatingLenderCity',\n"," 'OriginatingLenderState',\n"," 'Gender',\n"," 'Veteran',\n"," 'NonProfit',\n"," 'ForgivenessAmount',\n"," 'ForgivenessDate',\n"," 'forgiveness_date',\n"," 'date_approved',\n"," 'loan_status_date']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["ppp_df.columns"]},{"cell_type":"code","execution_count":10,"id":"433c3628","metadata":{},"outputs":[{"data":{"text/plain":["Index(['GeoFIPS', 'GeoName', 'Region', 'TableName', 'LineCode',\n","       'IndustryClassification', 'Description', 'Unit', '2017', '2018', '2019',\n","       '2020', '2021', '2022'],\n","      dtype='object')"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["gdp_df.columns"]},{"cell_type":"code","execution_count":11,"id":"5369e248","metadata":{},"outputs":[{"data":{"text/plain":["Index(['2022 NAICS US Code', '2022 NAICS US Title', 'industry_type'], dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["naics_df.columns"]},{"cell_type":"markdown","id":"db6cb13d","metadata":{},"source":["# Reformatting"]},{"cell_type":"code","execution_count":12,"id":"f562ef62","metadata":{},"outputs":[],"source":["# Changes a list of columns to a certain datatype. This is for PySpark dataframes.\n","# You give it... \n","#  1. The dataframe you want to modify\n","#  2. The list of strings for the name of columns you want to be modified\n","#  3. The datetype you want to modify them to\n","\n","def change_cols_to_type(df, list_of_columns, data_type):\n","    for column in list_of_columns:\n","        df = df.withColumn(column, df[column].cast(data_type))\n","    return df"]},{"cell_type":"code","execution_count":13,"id":"7d510662","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- LoanNumber: long (nullable = true)\n"," |-- DateApproved: string (nullable = true)\n"," |-- SBAOfficeCode: integer (nullable = true)\n"," |-- ProcessingMethod: string (nullable = true)\n"," |-- BorrowerName: string (nullable = true)\n"," |-- BorrowerAddress: string (nullable = true)\n"," |-- BorrowerCity: string (nullable = true)\n"," |-- BorrowerState: string (nullable = true)\n"," |-- BorrowerZip: string (nullable = true)\n"," |-- LoanStatusDate: string (nullable = true)\n"," |-- LoanStatus: string (nullable = true)\n"," |-- Term: string (nullable = true)\n"," |-- SBAGuarantyPercentage: float (nullable = true)\n"," |-- InitialApprovalAmount: float (nullable = true)\n"," |-- CurrentApprovalAmount: float (nullable = true)\n"," |-- UndisbursedAmount: float (nullable = true)\n"," |-- FranchiseName: string (nullable = true)\n"," |-- ServicingLenderLocationID: long (nullable = true)\n"," |-- ServicingLenderName: string (nullable = true)\n"," |-- ServicingLenderAddress: string (nullable = true)\n"," |-- ServicingLenderCity: string (nullable = true)\n"," |-- ServicingLenderState: string (nullable = true)\n"," |-- ServicingLenderZip: string (nullable = true)\n"," |-- RuralUrbanIndicator: string (nullable = true)\n"," |-- HubzoneIndicator: string (nullable = true)\n"," |-- LMIIndicator: string (nullable = true)\n"," |-- BusinessAgeDescription: string (nullable = true)\n"," |-- ProjectCity: string (nullable = true)\n"," |-- ProjectCountyName: string (nullable = true)\n"," |-- ProjectState: string (nullable = true)\n"," |-- ProjectZip: string (nullable = true)\n"," |-- CD: string (nullable = true)\n"," |-- JobsReported: float (nullable = true)\n"," |-- NAICSCode: string (nullable = true)\n"," |-- Race: string (nullable = true)\n"," |-- Ethnicity: string (nullable = true)\n"," |-- PAYROLL_PROCEED: string (nullable = true)\n"," |-- BusinessType: string (nullable = true)\n"," |-- OriginatingLenderLocationID: long (nullable = true)\n"," |-- OriginatingLender: string (nullable = true)\n"," |-- OriginatingLenderCity: string (nullable = true)\n"," |-- OriginatingLenderState: string (nullable = true)\n"," |-- Gender: string (nullable = true)\n"," |-- Veteran: string (nullable = true)\n"," |-- NonProfit: string (nullable = true)\n"," |-- ForgivenessAmount: float (nullable = true)\n"," |-- ForgivenessDate: string (nullable = true)\n"," |-- forgiveness_date: date (nullable = true)\n"," |-- date_approved: date (nullable = true)\n"," |-- loan_status_date: date (nullable = true)\n","\n"]}],"source":["ppp_df_cols_to_float = [\"InitialApprovalAmount\", \"CurrentApprovalAmount\",\n","                \"UndisbursedAmount\", \"ForgivenessAmount\", \n","                 \"SBAGuarantyPercentage\", \"JobsReported\"]\n","ppp_df_cols_to_long = [\"ServicingLenderLocationID\", \"OriginatingLenderLocationID\"]\n","\n","ppp_df = change_cols_to_type(ppp_df, ppp_df_cols_to_float, \"float\")\n","ppp_df = change_cols_to_type(ppp_df, ppp_df_cols_to_long, \"long\")\n","\n","#naics_df['2022 NAICS US Code'] = naics_df['2022 NAICS US Code'].astype(int)\n","\n","ppp_df.printSchema()"]},{"cell_type":"markdown","id":"0f71c0a2","metadata":{},"source":["# Function that creates ID's for columns in a Spark Dataframe"]},{"cell_type":"code","execution_count":14,"id":"9b6f012a","metadata":{},"outputs":[],"source":["def create_ids(df,id_column_name=None):\n","    #Transforms PySpark dataframe\n","    if isinstance(df, PySparkDataFrame):\n","        print(\"Transforming PySpark DataFrame...\")\n","        \n","        if id_column_name is None:\n","            id_column_name = \"id\"\n","        \n","        # Extract the original schema\n","        original_schema = df.schema\n","\n","        # Add an ID column using zipWithIndex\n","        df_with_index = (\n","            df.rdd\n","            .zipWithIndex()  # Add an index to each row\n","            .map(lambda x: Row(**dict(x[0].asDict(), id=x[1])))  # Add 'id' to each row\n","        )\n","\n","        # Define the new schema with the ID column added\n","        new_schema = original_schema.add(id_column_name, \"long\")\n","\n","        # Create a new DataFrame with the updated schema\n","        df_with_index = spark.createDataFrame(df_with_index, schema=new_schema)\n","        \n","        print(\"Completed transforming PySpark DataFrame.\")\n","        return df_with_index\n","    \n","    #No valid dataframe found\n","    else:\n","        print(\"ERROR: INVALID DATAFRAME - NO PROCEDURE APPLIED.\")\n","        print(\"Did you try inputting a PySpark Dataframe?\")"]},{"cell_type":"markdown","id":"5040b408","metadata":{},"source":["# Function to turn column names to snake_case"]},{"cell_type":"code","execution_count":15,"id":"6e73cb70","metadata":{},"outputs":[],"source":["#Turns any columns that has TheseColumnsNames to these_column_names\n","import re\n","from pyspark.sql import DataFrame as PySparkDataFrame\n","def name_to_snake_case(name):\n","    # Add underscores before capital letters, then convert to lowercase\n","    return re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()\n","\n","#Takes in any type of dataframe and turns its columns into snake_case\n","def df_to_snake_case(df):\n","    \n","    #Transforms PySpark dataframe\n","    if isinstance(df, PySparkDataFrame):\n","        print(\"Transforming PySpark DataFrame...\")\n","        # Rename all columns to snake_case\n","        snake_case_columns = [name_to_snake_case(col) for col in df.columns]\n","        df_snake_case = df.toDF(*snake_case_columns)\n","        print(\"Completed transforming PySpark DataFrame.\")\n","        return df_snake_case\n","    \n","    #Transforms Pandas dataframe\n","    elif isinstance(df, pd.DataFrame):\n","        print(\"Transforming Pandas DataFrame...\")\n","        # Rename all columns to snake_case\n","        df.columns = [name_to_snake_case(col) for col in df.columns]\n","        print(\"Completed transforming Pandas DataFrame.\")\n","        return df\n","    \n","    #No valid dataframe found\n","    else:\n","        print(\"ERROR: INVALID DATAFRAME - NO PROCEDURE APPLIED\")\n"]},{"cell_type":"code","execution_count":16,"id":"e42db538","metadata":{},"outputs":[],"source":["# initialize array. Append all dims and tables here. At the end, we loop through this list to save all dataframes.\n","tables = []"]},{"cell_type":"code","execution_count":17,"id":"ed97427f","metadata":{},"outputs":[],"source":["# Function to check how unique a column is. This will be used to verify all ID's in an ID column are unique.\n","def check_uniqueness(df, col_name):\n","    if isinstance(df, PySparkDataFrame):\n","        total_count = df.count()\n","        distinct_count = df.select(col_name).distinct().count()\n","    elif isinstance(df, pd.DataFrame):\n","        total_count = len(df)\n","        distinct_count = df[col_name].nunique()\n","\n","    if total_count == distinct_count:\n","        print(f\"The column '{col_name}' contains all unique values.\")\n","    else:\n","        print(f\"The column '{col_name}' contains duplicates. Total rows: {total_count}, Distinct rows: {distinct_count}\")"]},{"cell_type":"markdown","id":"428d8ec1","metadata":{},"source":["# Dim Borrower"]},{"cell_type":"code","execution_count":18,"id":"f1fc4c36","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----------+--------------------+--------------------+-------------+--------------+------------+--------------+------------------------+----------+--------------------+--------------------+------------+-----------+----------+\n","|borrower_id|       borrower_name|    borrower_address|borrower_city|borrower_state|borrower_zip|franchise_name|business_age_description|      race|           ethnicity|       business_type|      gender|    veteran|non_profit|\n","+-----------+--------------------+--------------------+-------------+--------------+------------+--------------+------------------------+----------+--------------------+--------------------+------------+-----------+----------+\n","| 9647258509|NEW MADISON AVENU...|    1 Silvermine Rdg|      Norwalk|            CT|  06850-1042|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 7781477805|HOMETECH SUNROOMS...|       499 berlin st|  Southington|            CT|  06489-3807|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Limited  Liabilit...|  Male Owned|Non-Veteran|      NULL|\n","| 7240757204|CHURCH OF GOD NEW...|         72 CEDAR ST|     HARTFORD|            CT|       06106|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Non-Profit Organi...|  Unanswered| Unanswered|         Y|\n","| 9236467207|    BOTTI REALTY INC|    368 DERBY AVENUE|        DERBY|            CT|       06418|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|         Corporation|  Unanswered| Unanswered|      NULL|\n","| 1745827406|     THE TIRE CENTER|       133 stiles st|    new haven|            CT|       06512|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Subchapter S Corp...|  Unanswered| Unanswered|      NULL|\n","| 8217858605|IRISH AMERICAN HO...|     132 Commerce St|  Glastonbury|            CT|  06033-2369|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Non-Profit Organi...|  Unanswered| Unanswered|         Y|\n","| 1533107302|GUERRERA MACHINE ...|          21 MARC DR|    WATERTOWN|            CT|       06795|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Subchapter S Corp...|  Unanswered| Unanswered|      NULL|\n","| 4377098810|VICTORY INTERNATI...|96 Columbus Pl 96...|     Stamford|            CT|  06907-1616|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 7954787204|LITERACY VOLUNTEE...|    7 WHITTLESEY AVE|  NEW MILFORD|            CT|  06776-3023|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Non-Profit Organi...|  Unanswered| Unanswered|         Y|\n","| 7659588501|COMPUTECH COMPLET...|       1496 Route 12|  Gales Ferry|            CT|  06335-1838|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Subchapter S Corp...|  Unanswered| Unanswered|      NULL|\n","| 8756368109|          LEETSTYLES|        2582 MAIN ST|     HARTFORD|            CT|  06120-1934|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 8295857408|TITAN CONSTRUCTIO...|       8 STANDISH RD|     COVENTRY|            CT|       06238|          NULL|    Existing or more ...|     White|Not Hispanic or L...|Limited  Liabilit...|  Male Owned|Non-Veteran|      NULL|\n","| 3543327410|NEW HAVEN FOOD MA...|        55 CHURCH ST|    NEW HAVEN|            CT|       06510|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|         Corporation|  Unanswered| Unanswered|      NULL|\n","| 6868507200|THE FLASH LADY PH...|     51 Gilbert Road|    Newington|            CT|       06111|          NULL|    Existing or more ...|     White|Not Hispanic or L...|Limited  Liabilit...|Female Owned|Non-Veteran|      NULL|\n","| 5899527204|GALEN LABORATORY ...|410 Sackett Point...|  North Haven|            CT|  06473-3106|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated| Sole Proprietorship|  Unanswered| Unanswered|      NULL|\n","| 5152967307|     WILD AND CO LLC|     70 HILLSIDE AVE|    WATERBURY|            CT|       06710|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","| 9944638806|WESTERN CONNECTIC...|       267 Chapel St|    New Haven|            CT|  06513-4214|          NULL|    Existing or more ...|Unanswered|Not Hispanic or L...|Non-Profit Organi...|  Male Owned|Non-Veteran|         Y|\n","| 9176918901|       ERIN MOLODICH|   581 Ekonk Hill Rd|       Moosup|            CT|  06354-2405|          NULL|    Existing or more ...|     White|Not Hispanic or L...| Sole Proprietorship|Female Owned|Non-Veteran|      NULL|\n","| 1694668107|        WENDY MURPHY|294 CHESTNUT HILL RD|       WILTON|            CT|  06897-3501|          NULL|    Existing or more ...|Unanswered|Not Hispanic or L...| Sole Proprietorship|Female Owned| Unanswered|      NULL|\n","| 3170528501|  KTZ MANAGEMENT LLC|    183 Race Hill Rd|      Madison|            CT|  06443-1692|          NULL|    Existing or more ...|Unanswered|   Unknown/NotStated|Limited  Liabilit...|  Unanswered| Unanswered|      NULL|\n","+-----------+--------------------+--------------------+-------------+--------------+------------+--------------+------------------------+----------+--------------------+--------------------+------------+-----------+----------+\n","only showing top 20 rows\n","\n"]},{"data":{"text/plain":["['borrower_id',\n"," 'borrower_name',\n"," 'borrower_address',\n"," 'borrower_city',\n"," 'borrower_state',\n"," 'borrower_zip',\n"," 'franchise_name',\n"," 'business_age_description',\n"," 'race',\n"," 'ethnicity',\n"," 'business_type',\n"," 'gender',\n"," 'veteran',\n"," 'non_profit']"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["#Create Dim\n","dim_borrower = ppp_df.select(\"LoanNumber\",\"BorrowerName\",\"BorrowerAddress\",\n","                            \"BorrowerCity\",\"BorrowerState\",\"BorrowerZip\",\n","                            \"FranchiseName\",\"BusinessAgeDescription\",\n","                            \"Race\",\"Ethnicity\",\"BusinessType\",\"Gender\",\n","                            \"Veteran\",\"NonProfit\")\n","\n","#Fix Names\n","dim_borrower = dim_borrower.withColumnRenamed(\"LoanNumber\",\"borrower_id\")\n","dim_borrower = df_to_snake_case(dim_borrower)\n","\n","#Remove duplicates\n","dim_borrower = dim_borrower.distinct()\n","\n","#Add to tables\n","tables.append([dim_borrower,\"dim_borrower\"])\n","\n","#Show\n","dim_borrower.show()\n","dim_borrower.columns"]},{"cell_type":"markdown","id":"2f0290a4","metadata":{},"source":["# Dim SBA office"]},{"cell_type":"code","execution_count":19,"id":"01682035","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 8:====================================================>     (9 + 1) / 10]\r"]},{"name":"stdout","output_type":"stream","text":["Transforming Pandas DataFrame...\n","Completed transforming Pandas DataFrame.\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SBA_office_code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>914</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>811</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>474</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>299</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>130</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>341</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>172</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>721</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>875</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>76 rows × 1 columns</p>\n","</div>"],"text/plain":["    SBA_office_code\n","0               914\n","1               811\n","2               474\n","3               299\n","4               358\n","..              ...\n","71              130\n","72              341\n","73              172\n","74              721\n","75              875\n","\n","[76 rows x 1 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["#Create Dim\n","dim_SBA_office = ppp_df.select(\"SBAOfficeCode\").distinct().toPandas()\n","\n","#Fix Names\n","dim_SBA_office = df_to_snake_case(dim_SBA_office)\n","dim_SBA_office.rename(columns={'s_b_a_office_code':'SBA_office_code'}, inplace=True)\n","\n","#Remove duplicates\n","dim_SBA_office = dim_SBA_office.drop_duplicates()\n","\n","#Add to tables\n","tables.append([dim_SBA_office,\"dim_SBA_office\"])\n","\n","#Show\n","dim_SBA_office"]},{"cell_type":"markdown","id":"c020973f","metadata":{},"source":["# Dim Processing Method"]},{"cell_type":"code","execution_count":20,"id":"2499da32","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 11:===================================================>     (9 + 1) / 10]\r"]},{"name":"stdout","output_type":"stream","text":["Transforming Pandas DataFrame...\n","Completed transforming Pandas DataFrame.\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>processing_method</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PPP</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PPS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  processing_method\n","0               PPP\n","1               PPS"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["#Create Dim\n","dim_processing_method = ppp_df.select(\"ProcessingMethod\").distinct().toPandas()\n","\n","#Fix Names\n","dim_processing_method = df_to_snake_case(dim_processing_method)\n","\n","#Remove duplicates\n","dim_processing_method = dim_processing_method.drop_duplicates()\n","\n","#Add to tables\n","tables.append([dim_processing_method,\"dim_processing_method\"])\n","\n","#Show\n","dim_processing_method"]},{"cell_type":"markdown","id":"b6bf6b3d","metadata":{},"source":["# Dim Originating Lender"]},{"cell_type":"code","execution_count":21,"id":"5f738cf0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 14:===================================================>     (9 + 1) / 10]\r"]},{"name":"stdout","output_type":"stream","text":["+------------------------------+--------------------+-----------------------+------------------------+\n","|originating_lender_location_id|  originating_lender|originating_lender_city|originating_lender_state|\n","+------------------------------+--------------------+-----------------------+------------------------+\n","|                         25001| First Heritage Bank|             Shenandoah|                      IA|\n","|                        532784|        People Trust|            Little Rock|                      AR|\n","|                        448174|     Millennium Bank|            DES PLAINES|                      IL|\n","|                        238179|Cedar Rapids Bank...|           Cedar Rapids|                      IA|\n","|                        124107|       Highland Bank|                    Ely|                      MN|\n","|                        119777|      Builtwell Bank|                 Dalton|                      GA|\n","|                        123532|           NBKC Bank|                Leawood|                      KS|\n","|                         25727|the Farmers State...|                BUCKLIN|                      KS|\n","|                        107050|EastRise Federal ...|             Montpelier|                      VT|\n","|                         97969|Atlantic Regional...|         South Portland|                      ME|\n","|                         40230|          Focus Bank|             CHARLESTON|                      MO|\n","|                        462816|Hanover Community...|                Mineola|                      NY|\n","|                        438048|TPF Loan Corporation|          Hollidaysburg|                      PA|\n","|                         14935|Savings Bank of M...|                  UKIAH|                      CA|\n","|                        118097|    BayVanguard Bank|                 EASTON|                      MD|\n","|                        447956| Texas Partners Bank|            SAN ANTONIO|                      TX|\n","|                         57656|Kingston National...|               KINGSTON|                      OH|\n","|                        101808|       Ukrainian FCU|              ROCHESTER|                      NY|\n","|                        512613|International Ban...|          OKLAHOMA CITY|                      OK|\n","|                         21297|     Crossroads Bank|              EFFINGHAM|                      IL|\n","+------------------------------+--------------------+-----------------------+------------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["#Create Dim\n","dim_originating_lender = ppp_df.select(\"OriginatingLenderLocationID\",\n","                                      \"OriginatingLender\",\"OriginatingLenderCity\",\n","                                      \"OriginatingLenderState\")\n","\n","#Fix Names\n","dim_originating_lender = df_to_snake_case(dim_originating_lender)\n","dim_originating_lender = dim_originating_lender.withColumnRenamed(\"originating_lender_location_i_d\",\"originating_lender_location_id\")\n","\n","#Remove duplicates\n","dim_originating_lender = dim_originating_lender.distinct()\n","\n","#Add to tables\n","tables.append([dim_originating_lender,\"dim_originating_lender\"])\n","\n","#Show\n","dim_originating_lender.show()"]},{"cell_type":"markdown","id":"9846d215","metadata":{},"source":["# Dim Servicing Lender"]},{"cell_type":"code","execution_count":22,"id":"5f383733","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 17:===================================================>     (9 + 1) / 10]\r"]},{"name":"stdout","output_type":"stream","text":["+----------------------------+---------------------+------------------------+---------------------+----------------------+--------------------+\n","|servicing_lender_location_id|servicing_lender_name|servicing_lender_address|servicing_lender_city|servicing_lender_state|servicing_lender_zip|\n","+----------------------------+---------------------+------------------------+---------------------+----------------------+--------------------+\n","|                       39197|  The Commercial Bank|           175 Hopper St|              DE KALB|                    MS|          39328-9808|\n","|                      107793| Washington State ...|        330 Union Ave SE|              OLYMPIA|                    WA|          98501-2062|\n","|                      122100| Neighborhood Nati...|         2987 Jamacha Rd|             EL CAJON|                    CA|               92019|\n","|                       96495|     Three Rivers FCU|     1615 Northland Blvd|           FORT WAYNE|                    IN|          46825-6554|\n","|                       69183| The Donley County...|           201 S Kearney|            CLARENDON|                    TX|               79226|\n","|                       41769|             FMB Bank|    100 Veterans Memo...|          WRIGHT CITY|                    MO|          63390-1101|\n","|                       15674| The Citizens Stat...|             600 Main St|                OURAY|                    CO|               81427|\n","|                       59268| Peoples Bank and ...|        2400 NW 178th St|               Edmond|                    OK|               73012|\n","|                       25818| The Lyon County S...|         902 Merchant St|              EMPORIA|                    KS|          66801-2814|\n","|                       73903|           First Bank|           112 W King St|            STRASBURG|                    VA|          22657-2220|\n","|                       42368| Corn Growers Stat...|         333 Nebraska St|              MURDOCK|                    NE|          68407-8407|\n","|                       25825|     Flint Hills Bank|       103 1/2 N Main St|             ESKRIDGE|                    KS|               66423|\n","|                       28425|    Marion State Bank|             345 Main St|               MARION|                    LA|          71260-5253|\n","|                      444912|   Lewis & Clark Bank|      15960 S. Agnes Ave|          Oregon City|                    OR|               97045|\n","|                       39047| Ultima Bank Minne...|      9, W Minnesota Ave|               Winger|                    MN|               56592|\n","|                       40544|      Bank of Grandin|           504, W 5th St|              Grandin|                    MO|               63943|\n","|                       71430|     First State Bank|    2118 S Treadaway ...|              ABILENE|                    TX|          79602-5906|\n","|                      102478| North Star Commun...|         109 Central Ave|              MADDOCK|                    ND|          58348-7205|\n","|                       92358| America's Christi...|    2100 E Rte 66, St...|             GLENDORA|                    CA|          91740-4623|\n","|                       72203| International Ban...|    US Hwy 83 at 10th...|               ZAPATA|                    TX|          78076-1030|\n","+----------------------------+---------------------+------------------------+---------------------+----------------------+--------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["#Create Dim\n","dim_servicing_lender = ppp_df.select('ServicingLenderLocationID', 'ServicingLenderName',\n","                                     'ServicingLenderAddress', 'ServicingLenderCity', \n","                                     'ServicingLenderState','ServicingLenderZip')\n","\n","#Fix Names\n","dim_servicing_lender = df_to_snake_case(dim_servicing_lender)\n","dim_servicing_lender = dim_servicing_lender.withColumnRenamed(\"servicing_lender_location_i_d\",\"servicing_lender_location_id\")\n","\n","#Remove duplicates\n","dim_servicing_lender = dim_servicing_lender.distinct()\n","\n","#Add to tables\n","tables.append([dim_servicing_lender,\"dim_servicing_lender\"])\n","\n","#Show\n","dim_servicing_lender.show()"]},{"cell_type":"markdown","id":"b4ac5411","metadata":{},"source":["# Dim Date"]},{"cell_type":"code","execution_count":23,"id":"66b509cf","metadata":{"scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>date_id</th>\n","      <th>year_number</th>\n","      <th>month_number</th>\n","      <th>day_number</th>\n","      <th>week_number</th>\n","      <th>week_of_month</th>\n","      <th>week_of_year</th>\n","      <th>month_name</th>\n","      <th>day_name</th>\n","      <th>timestamp_isoformat</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-01-01</td>\n","      <td>20170101</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Sunday</td>\n","      <td>2017-01-01T00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-01-02</td>\n","      <td>20170102</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>01</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Monday</td>\n","      <td>2017-01-02T00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-01-03</td>\n","      <td>20170103</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>01</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Tuesday</td>\n","      <td>2017-01-03T00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-01-04</td>\n","      <td>20170104</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>01</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Wednesday</td>\n","      <td>2017-01-04T00:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-01-05</td>\n","      <td>20170105</td>\n","      <td>2017</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>01</td>\n","      <td>1</td>\n","      <td>01</td>\n","      <td>January</td>\n","      <td>Thursday</td>\n","      <td>2017-01-05T00:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        date   date_id  year_number  month_number  day_number week_number  \\\n","0 2017-01-01  20170101         2017             1           1          52   \n","1 2017-01-02  20170102         2017             1           2          01   \n","2 2017-01-03  20170103         2017             1           3          01   \n","3 2017-01-04  20170104         2017             1           4          01   \n","4 2017-01-05  20170105         2017             1           5          01   \n","\n","   week_of_month week_of_year month_name   day_name  timestamp_isoformat  \n","0              1           01    January     Sunday  2017-01-01T00:00:00  \n","1              1           01    January     Monday  2017-01-02T00:00:00  \n","2              1           01    January    Tuesday  2017-01-03T00:00:00  \n","3              1           01    January  Wednesday  2017-01-04T00:00:00  \n","4              1           01    January   Thursday  2017-01-05T00:00:00  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["def week_of_month(dt):\n","    year = dt.year\n","    month = dt.month\n","    day = dt.day\n","    \n","    cal = calendar.monthcalendar(year,month)\n","    week_number = (day - 1) // 7 + 1\n","    return week_number\n","\n","    \n","#Create Dim\n","start_date = pd.to_datetime(\"2017-01-01\")\n","end_date = pd.to_datetime(\"2022-12-31\")\n","\n","dim_date = pd.DataFrame({\"date\": pd.date_range(start_date, end_date, freq=\"D\")})\n","\n","dim_date['date_id'] = dim_date['date'].dt.strftime('%Y%m%d')\n","dim_date['year_number'] = dim_date['date'].dt.year\n","dim_date['month_number'] = dim_date['date'].dt.month\n","dim_date['day_number'] = dim_date['date'].dt.day\n","dim_date['week_number'] = dim_date['date'].dt.strftime('%V')\n","dim_date['week_of_month'] = dim_date['date'].apply(week_of_month)\n","dim_date['week_of_year'] = dim_date['date'].dt.strftime('%U')\n","dim_date['month_name'] = dim_date['date'].dt.strftime('%B')\n","dim_date['day_name'] = dim_date['date'].dt.strftime('%A')\n","dim_date['timestamp_isoformat'] = dim_date['date'].apply(lambda x: x.isoformat())\n","\n","#Add to tables\n","tables.append([dim_date,\"dim_date\"])\n","\n","#Show\n","#print(dim_date.shape)\n","#print(dim_date.info())\n","#print(dim_date.head())\n","dim_date.head()"]},{"cell_type":"markdown","id":"966df06b","metadata":{},"source":["# Dim Industry"]},{"cell_type":"code","execution_count":24,"id":"d260522f","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2022 NAICS US Code</th>\n","      <th>2022 NAICS US Title</th>\n","      <th>industry_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111</td>\n","      <td>Crop Production</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1111</td>\n","      <td>Oilseed and Grain Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11111</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>111110</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2120</th>\n","      <td>9281</td>\n","      <td>National Security and International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2121</th>\n","      <td>92811</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2122</th>\n","      <td>928110</td>\n","      <td>National Security</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2123</th>\n","      <td>92812</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","    <tr>\n","      <th>2124</th>\n","      <td>928120</td>\n","      <td>International Affairs</td>\n","      <td>Public Administration</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2125 rows × 3 columns</p>\n","</div>"],"text/plain":["     2022 NAICS US Code                           2022 NAICS US Title  \\\n","0                    11    Agriculture, Forestry, Fishing and Hunting   \n","1                   111                               Crop Production   \n","2                  1111                     Oilseed and Grain Farming   \n","3                 11111                               Soybean Farming   \n","4                111110                               Soybean Farming   \n","...                 ...                                           ...   \n","2120               9281  National Security and International Affairs    \n","2121              92811                            National Security    \n","2122             928110                            National Security    \n","2123              92812                        International Affairs    \n","2124             928120                        International Affairs    \n","\n","                                   industry_type  \n","0     Agriculture, Forestry, Fishing and Hunting  \n","1     Agriculture, Forestry, Fishing and Hunting  \n","2     Agriculture, Forestry, Fishing and Hunting  \n","3     Agriculture, Forestry, Fishing and Hunting  \n","4     Agriculture, Forestry, Fishing and Hunting  \n","...                                          ...  \n","2120                       Public Administration  \n","2121                       Public Administration  \n","2122                       Public Administration  \n","2123                       Public Administration  \n","2124                       Public Administration  \n","\n","[2125 rows x 3 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["naics_df"]},{"cell_type":"code","execution_count":25,"id":"0908cb5e","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>NAICS_code</th>\n","      <th>industry_name</th>\n","      <th>industry_type</th>\n","      <th>industry_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111</td>\n","      <td>Crop Production</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1111</td>\n","      <td>Oilseed and Grain Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11111</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>111110</td>\n","      <td>Soybean Farming</td>\n","      <td>Agriculture, Forestry, Fishing and Hunting</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  NAICS_code                               industry_name  \\\n","0         11  Agriculture, Forestry, Fishing and Hunting   \n","1        111                             Crop Production   \n","2       1111                   Oilseed and Grain Farming   \n","3      11111                             Soybean Farming   \n","4     111110                             Soybean Farming   \n","\n","                                industry_type  industry_id  \n","0  Agriculture, Forestry, Fishing and Hunting            1  \n","1  Agriculture, Forestry, Fishing and Hunting            2  \n","2  Agriculture, Forestry, Fishing and Hunting            3  \n","3  Agriculture, Forestry, Fishing and Hunting            4  \n","4  Agriculture, Forestry, Fishing and Hunting            5  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["#Create Dim\n","dim_industry = pd.DataFrame()\n","dim_industry['NAICS_code'] = naics_df['2022 NAICS US Code']\n","dim_industry['industry_name'] = naics_df['2022 NAICS US Title']\n","dim_industry['industry_type'] = naics_df['industry_type']\n","\n","#Add unique ID\n","dim_industry['industry_id'] = pd.factorize(dim_industry['NAICS_code'])[0] + 1\n","\n","#Remove duplicates\n","dim_industry = dim_industry.drop_duplicates()\n","\n","#Add to tables\n","tables.append([dim_industry,\"dim_industry\"])\n","\n","#Show\n","dim_industry.head()"]},{"cell_type":"markdown","id":"c3ff1781","metadata":{},"source":["# Dim Census Location\n"]},{"cell_type":"code","execution_count":26,"id":"4018470f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#Create Dim\n","dim_census_location = ppp_df.select('ProjectCity','ProjectCountyName', \n","                                    'ProjectState', 'ProjectZip','CD')\n","dim_cen_count_BEFORE = dim_census_location.count()"]},{"cell_type":"code","execution_count":27,"id":"b44e345f","metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n","Transforming PySpark DataFrame...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Completed transforming PySpark DataFrame.\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 26:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+-------------------+-------------+-----------+-----+------------------+\n","|   project_city|project_county_name|project_state|project_zip|   cd|census_location_id|\n","+---------------+-------------------+-------------+-----------+-----+------------------+\n","|         SMYRNA|               COBB|           GA| 30080-3002|GA-11|               320|\n","|       MARIETTA|               COBB|           GA| 30068-4353|GA-06|              1995|\n","|         Warner|            HOUSTON|           GA| 31088-0300|GA-08|              2561|\n","|         ATHENS|             CLARKE|           GA| 30601-1952|GA-10|              2636|\n","|      MCDONOUGH|              HENRY|           GA| 30253-8034|GA-13|              2950|\n","|        EMERSON|             BARTOW|           GA| 30137-2219|GA-11|              4128|\n","|    STOCKBRIDGE|              HENRY|           GA| 30281-1196|GA-13|              4845|\n","|  Lawrenceville|           GWINNETT|           GA| 30046-5753|GA-07|              4950|\n","|       TAMUNING|               GUAM|           GU| 96931-7026|  GU-|              5346|\n","|       Honolulu|           HONOLULU|           HI| 96815-1851|HI-01|              9128|\n","|          LIHUE|              KAUAI|           HI| 96766-9062|HI-02|              9160|\n","|       Honolulu|           HONOLULU|           HI| 96826-3324|HI-01|              9865|\n","|        Wahiawa|           HONOLULU|           HI| 96786-2169|HI-02|              9898|\n","|       Honolulu|           HONOLULU|           HI| 96817-4311|HI-01|              9927|\n","|   CEDAR RAPIDS|               LINN|           IA| 52401-1500|IA-02|             10227|\n","|      WINTERSET|            MADISON|           IA| 50273-1365|IA-03|             10236|\n","|      Davenport|              SCOTT|           IA| 52807-3203|IA-01|             10910|\n","|WEST DES MOINES|               POLK|           IA| 50266-0001|IA-03|             11005|\n","|     BETTENDORF|              SCOTT|           IA| 52722-5038|IA-01|             11067|\n","|      URBANDALE|               POLK|           IA| 50322-7919|IA-03|             11379|\n","+---------------+-------------------+-------------+-----------+-----+------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["#Fix Names\n","dim_census_location = dim_census_location.withColumnRenamed(\"CD\",\"cd\")\n","dim_census_location = df_to_snake_case(dim_census_location)\n","\n","#Add unique ID\n","dim_census_location = create_ids(dim_census_location, \"census_location_id\")\n","\n","#Remove duplicates\n","dim_census_location = dim_census_location.distinct()\n","\n","#Add to tables\n","tables.append([dim_census_location,\"dim_census_location\"])\n","\n","#Show\n","dim_census_location.show()"]},{"cell_type":"markdown","id":"38a559a6","metadata":{},"source":["# Facts GDP"]},{"cell_type":"code","execution_count":28,"id":"3bb2fc3c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming Pandas DataFrame...\n","Completed transforming Pandas DataFrame.\n"]}],"source":["#Create facts\n","facts_gdp = gdp_df\n","\n","#Fix names\n","facts_gdp = df_to_snake_case(facts_gdp)\n","facts_gdp.rename(columns={'geo_f_i_p_s':'geofips'}, inplace=True)\n","\n","#Remove duplicates\n","facts_gdp = facts_gdp.drop_duplicates()\n","\n","#Drop unnecessary columns\n","facts_gdp.drop('industry_classification',axis=1,inplace=True)"]},{"cell_type":"code","execution_count":29,"id":"47c4142e","metadata":{},"outputs":[],"source":["# Convert columns 2017-2022 to float\n","columns_to_convert = ['2017', '2018', '2019', '2020', '2021', '2022']\n","\n","# Convert columns to float while replacing invalid entries with NaN\n","facts_gdp[columns_to_convert] = facts_gdp[columns_to_convert].apply(pd.to_numeric, errors='coerce')"]},{"cell_type":"code","execution_count":30,"id":"76130016","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>geofips</th>\n","      <th>geo_name</th>\n","      <th>region</th>\n","      <th>table_name</th>\n","      <th>line_code</th>\n","      <th>description</th>\n","      <th>unit</th>\n","      <th>2017</th>\n","      <th>2018</th>\n","      <th>2019</th>\n","      <th>2020</th>\n","      <th>2021</th>\n","      <th>2022</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>2.166155e+08</td>\n","      <td>2.208088e+08</td>\n","      <td>2.249446e+08</td>\n","      <td>2.220814e+08</td>\n","      <td>2.318926e+08</td>\n","      <td>2.358073e+08</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>1.000000e+02</td>\n","      <td>1.019360e+02</td>\n","      <td>1.038450e+02</td>\n","      <td>1.025230e+02</td>\n","      <td>1.070530e+02</td>\n","      <td>1.088600e+02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000</td>\n","      <td>Alabama</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>2.166155e+08</td>\n","      <td>2.262638e+08</td>\n","      <td>2.345264e+08</td>\n","      <td>2.351183e+08</td>\n","      <td>2.579865e+08</td>\n","      <td>2.815690e+08</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1001</td>\n","      <td>Autauga, AL</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>1.762558e+06</td>\n","      <td>1.787534e+06</td>\n","      <td>1.730861e+06</td>\n","      <td>1.722438e+06</td>\n","      <td>1.727818e+06</td>\n","      <td>1.929264e+06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1001</td>\n","      <td>Autauga, AL</td>\n","      <td>5.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>1.000000e+02</td>\n","      <td>1.014170e+02</td>\n","      <td>9.820200e+01</td>\n","      <td>9.772400e+01</td>\n","      <td>9.802900e+01</td>\n","      <td>1.094580e+02</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9526</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>1.000000e+02</td>\n","      <td>1.045590e+02</td>\n","      <td>1.095520e+02</td>\n","      <td>1.093290e+02</td>\n","      <td>1.166610e+02</td>\n","      <td>1.193240e+02</td>\n","    </tr>\n","    <tr>\n","      <th>9527</th>\n","      <td>97000</td>\n","      <td>Rocky Mountain</td>\n","      <td>7.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>6.813101e+08</td>\n","      <td>7.305677e+08</td>\n","      <td>7.762811e+08</td>\n","      <td>7.812724e+08</td>\n","      <td>8.801425e+08</td>\n","      <td>9.746826e+08</td>\n","    </tr>\n","    <tr>\n","      <th>9528</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>1</td>\n","      <td>Real GDP (thousands of chained 2017 dollars)</td>\n","      <td>Thousands of chained 2017 dollars</td>\n","      <td>3.797440e+09</td>\n","      <td>3.956948e+09</td>\n","      <td>4.108526e+09</td>\n","      <td>4.048650e+09</td>\n","      <td>4.342903e+09</td>\n","      <td>4.385658e+09</td>\n","    </tr>\n","    <tr>\n","      <th>9529</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>2</td>\n","      <td>Chain-type quantity indexes for real GDP</td>\n","      <td>Quantity index</td>\n","      <td>1.000000e+02</td>\n","      <td>1.042000e+02</td>\n","      <td>1.081920e+02</td>\n","      <td>1.066150e+02</td>\n","      <td>1.143640e+02</td>\n","      <td>1.154900e+02</td>\n","    </tr>\n","    <tr>\n","      <th>9530</th>\n","      <td>98000</td>\n","      <td>Far West</td>\n","      <td>8.0</td>\n","      <td>CAGDP1</td>\n","      <td>3</td>\n","      <td>Current-dollar GDP (thousands of current dolla...</td>\n","      <td>Thousands of dollars</td>\n","      <td>3.797440e+09</td>\n","      <td>4.026579e+09</td>\n","      <td>4.252235e+09</td>\n","      <td>4.254017e+09</td>\n","      <td>4.732878e+09</td>\n","      <td>5.066774e+09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9531 rows × 13 columns</p>\n","</div>"],"text/plain":["      geofips        geo_name  region table_name  line_code  \\\n","0        1000         Alabama     5.0     CAGDP1          1   \n","1        1000         Alabama     5.0     CAGDP1          2   \n","2        1000         Alabama     5.0     CAGDP1          3   \n","3        1001     Autauga, AL     5.0     CAGDP1          1   \n","4        1001     Autauga, AL     5.0     CAGDP1          2   \n","...       ...             ...     ...        ...        ...   \n","9526    97000  Rocky Mountain     7.0     CAGDP1          2   \n","9527    97000  Rocky Mountain     7.0     CAGDP1          3   \n","9528    98000        Far West     8.0     CAGDP1          1   \n","9529    98000        Far West     8.0     CAGDP1          2   \n","9530    98000        Far West     8.0     CAGDP1          3   \n","\n","                                            description  \\\n","0         Real GDP (thousands of chained 2017 dollars)    \n","1             Chain-type quantity indexes for real GDP    \n","2     Current-dollar GDP (thousands of current dolla...   \n","3         Real GDP (thousands of chained 2017 dollars)    \n","4             Chain-type quantity indexes for real GDP    \n","...                                                 ...   \n","9526          Chain-type quantity indexes for real GDP    \n","9527  Current-dollar GDP (thousands of current dolla...   \n","9528      Real GDP (thousands of chained 2017 dollars)    \n","9529          Chain-type quantity indexes for real GDP    \n","9530  Current-dollar GDP (thousands of current dolla...   \n","\n","                                   unit          2017          2018  \\\n","0     Thousands of chained 2017 dollars  2.166155e+08  2.208088e+08   \n","1                        Quantity index  1.000000e+02  1.019360e+02   \n","2                  Thousands of dollars  2.166155e+08  2.262638e+08   \n","3     Thousands of chained 2017 dollars  1.762558e+06  1.787534e+06   \n","4                        Quantity index  1.000000e+02  1.014170e+02   \n","...                                 ...           ...           ...   \n","9526                     Quantity index  1.000000e+02  1.045590e+02   \n","9527               Thousands of dollars  6.813101e+08  7.305677e+08   \n","9528  Thousands of chained 2017 dollars  3.797440e+09  3.956948e+09   \n","9529                     Quantity index  1.000000e+02  1.042000e+02   \n","9530               Thousands of dollars  3.797440e+09  4.026579e+09   \n","\n","              2019          2020          2021          2022  \n","0     2.249446e+08  2.220814e+08  2.318926e+08  2.358073e+08  \n","1     1.038450e+02  1.025230e+02  1.070530e+02  1.088600e+02  \n","2     2.345264e+08  2.351183e+08  2.579865e+08  2.815690e+08  \n","3     1.730861e+06  1.722438e+06  1.727818e+06  1.929264e+06  \n","4     9.820200e+01  9.772400e+01  9.802900e+01  1.094580e+02  \n","...            ...           ...           ...           ...  \n","9526  1.095520e+02  1.093290e+02  1.166610e+02  1.193240e+02  \n","9527  7.762811e+08  7.812724e+08  8.801425e+08  9.746826e+08  \n","9528  4.108526e+09  4.048650e+09  4.342903e+09  4.385658e+09  \n","9529  1.081920e+02  1.066150e+02  1.143640e+02  1.154900e+02  \n","9530  4.252235e+09  4.254017e+09  4.732878e+09  5.066774e+09  \n","\n","[9531 rows x 13 columns]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["#Show\n","facts_gdp"]},{"cell_type":"markdown","id":"6ba1a5a9","metadata":{},"source":["#### Now we will begin the process of connecting facts_gdp with dim_census_location"]},{"cell_type":"code","execution_count":31,"id":"8662fcbd","metadata":{},"outputs":[],"source":["# Start by converting facts_gdp to a spark df so we can work on it better\n","facts_gdp_spark = spark.createDataFrame(facts_gdp)"]},{"cell_type":"code","execution_count":32,"id":"331699e3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+------------------+------------------+\n","|            geo_name|       county_name|state_abbreviation|\n","+--------------------+------------------+------------------+\n","|       St. Johns, FL|         St. Johns|                FL|\n","|           Lamar, TX|             Lamar|                TX|\n","|        Stephens, OK|          Stephens|                OK|\n","|       Habersham, GA|         Habersham|                GA|\n","|          Gibson, TN|            Gibson|                TN|\n","|           Essex, VA|             Essex|                VA|\n","|    King William, VA|      King William|                VA|\n","|        Montague, TX|          Montague|                TX|\n","|Petersburg Boroug...|Petersburg Borough|               AK*|\n","|         Andrews, TX|           Andrews|                TX|\n","+--------------------+------------------+------------------+\n","\n"]}],"source":["#Next, we split the geo_name column so we can easily get the county name and state abbriviation\n","facts_gdp_spark = facts_gdp_spark.withColumn(\"county_name\", split(col(\"geo_name\"), \",\")[0])\n","facts_gdp_spark = facts_gdp_spark.withColumn(\"state_abbreviation\", trim(split(col(\"geo_name\"), \",\")[1]))\n","facts_gdp_spark.select(\"geo_name\",\"county_name\",\"state_abbreviation\").orderBy(rand()).limit(10).show()"]},{"cell_type":"code","execution_count":33,"id":"6fe8d280","metadata":{},"outputs":[],"source":["# quickly get the count of rows before we set the df to the joined df. This is for debugging purposes\n","facts_gpd_spark_before_count = facts_gdp_spark.count()"]},{"cell_type":"code","execution_count":34,"id":"b34b3337","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 38:=============================================>            (7 + 2) / 9]\r"]},{"name":"stdout","output_type":"stream","text":["+------------+------------------+-------------------+-------------+-----------+-----+------------------+\n","| county_name|state_abbreviation|project_county_name|project_state|project_zip|   cd|census_location_id|\n","+------------+------------------+-------------------+-------------+-----------+-----+------------------+\n","|Contra Costa|                CA|       CONTRA COSTA|           CA| 94523-0001|CA-10|           7129229|\n","| Los Angeles|                CA|        LOS ANGELES|           CA| 91307-2652|CA-32|           5274745|\n","| Bartholomew|                IN|        BARTHOLOMEW|           IN| 47244-9772|IN-06|           3661941|\n","|       Davis|                UT|              DAVIS|           UT| 84087-1038|UT-02|           4123402|\n","|      Nassau|                NY|             NASSAU|           NY| 11753-0001|NY-03|           8303927|\n","|    Hartford|                CT|           HARTFORD|           CT| 06110-0001|CT-01|            730555|\n","|       Henry|                OH|              HENRY|           OH| 43545-0001|OH-05|           2251647|\n","|        Cook|                IL|               COOK|           IL| 60651-1509|IL-07|           9823445|\n","|   Middlesex|                MA|          MIDDLESEX|           MA| 01746-3405|MA-02|            128763|\n","|      Carter|                OK|             CARTER|           OK| 73402-1202|OK-04|           2315015|\n","+------------+------------------+-------------------+-------------+-----------+-----+------------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# Clean the state abbreviations (e.g., removing any \"*\" characters)\n","df1_cleaned = facts_gdp_spark.withColumn(\"state_abbreviation\", regexp_replace(\"state_abbreviation\", r\"\\*\", \"\"))\n","df2_cleaned = dim_census_location.withColumn(\"project_state\", regexp_replace(\"project_state\", r\"\\*\", \"\"))\n","\n","# Make join condition (which is also case insensitive)\n","join_condition = (lower(col(\"df1.county_name\")) == lower(col(\"df2.project_county_name\"))) & \\\n","                 (lower(col(\"df1.state_abbreviation\")) == lower(col(\"df2.project_state\")))\n","\n","# Perform the join\n","joined_df = df1_cleaned.alias(\"df1\").join(df2_cleaned.alias(\"df2\"), on=join_condition, how=\"left\")\n","\n","# Show the result\n","joined_df.select(\"county_name\",\"state_abbreviation\",\"project_county_name\",\n","                 \"project_state\",\"project_zip\",\"cd\", \"census_location_id\").orderBy(rand()).limit(10).show()"]},{"cell_type":"code","execution_count":35,"id":"1494d9c8","metadata":{},"outputs":[],"source":["# Set facts_gdp_spark to new joined_df, then delete joined df\n","facts_gdp_spark = joined_df\n","del joined_df"]},{"cell_type":"code","execution_count":36,"id":"973ae9e6","metadata":{},"outputs":[],"source":["# Finally, we drop columns thats not needed\n","facts_gdp_spark.columns\n","facts_gdp_spark = facts_gdp_spark.drop(\"county_name\",\"state_abbreviation\", \"project_county_name\",\n","                                      \"project_state\", \"project_city\",\"project_zip\",\"cd\")"]},{"cell_type":"code","execution_count":37,"id":"3c91298e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 54:>                                                         (0 + 8) / 9]\r"]},{"name":"stdout","output_type":"stream","text":["Fact_GPD_SPARK_BEFORE: 9531\n","Fact_GPD_SPARK_AFTER: 29915703\n","Fact_GPD_PANDAS: 9531\n","DIM_Census_Location: 10406068\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 54:======================================>                   (6 + 3) / 9]\r","\r","                                                                                \r"]}],"source":["# See how much we changed facts_gpd\n","facts_gpd_spark_after_count = facts_gdp_spark.count()\n","facts_gpd_pandas_count =len(facts_gdp)\n","dim_census_location_count = dim_census_location.count()\n","\n","#Remove duplicates\n","facts_gdp_spark = facts_gdp_spark.distinct()\n","\n","print(\"Fact_GPD_SPARK_BEFORE: \"+str(facts_gpd_spark_before_count))\n","print(\"Fact_GPD_SPARK_AFTER: \"+str(facts_gpd_spark_after_count))\n","print(\"Fact_GPD_PANDAS: \"+str(facts_gpd_pandas_count))\n","print(\"DIM_Census_Location: \"+str(dim_census_location_count))"]},{"cell_type":"code","execution_count":38,"id":"4ffd43a3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: handyspark in /opt/conda/miniconda3/lib/python3.11/site-packages (0.2.2a1)\n","Requirement already satisfied: pyspark in /usr/lib/spark/python (from handyspark) (3.5.1)\n","Requirement already satisfied: matplotlib in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (3.8.4)\n","Requirement already satisfied: numpy in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (1.26.4)\n","Requirement already satisfied: scipy in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (1.11.4)\n","Requirement already satisfied: seaborn in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (0.13.2)\n","Requirement already satisfied: pandas in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (2.1.4)\n","Requirement already satisfied: scikit-learn in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (1.3.2)\n","Requirement already satisfied: findspark in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (2.0.1)\n","Requirement already satisfied: pyarrow in /opt/conda/miniconda3/lib/python3.11/site-packages (from handyspark) (14.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (23.1)\n","Requirement already satisfied: pillow>=8 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/miniconda3/lib/python3.11/site-packages (from matplotlib->handyspark) (2.9.0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->handyspark) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->handyspark) (2024.2)\n","Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pyspark->handyspark) (0.10.9.7)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from scikit-learn->handyspark) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from scikit-learn->handyspark) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->handyspark) (1.16.0)\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/spark/python/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n","  warnings.warn(\n","/usr/lib/spark/python/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n","  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n","                                                                                \r"]},{"data":{"text/plain":["geofips                 0\n","geo_name                0\n","region                  0\n","table_name              0\n","line_code               0\n","description             0\n","unit                    0\n","2017                    0\n","2018                    0\n","2019                    0\n","2020                    0\n","2021                    0\n","2022                    0\n","census_location_id    513\n","Name: missing, dtype: int64"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Check how much of facts_gdp is null after join\n","!pip install handyspark\n","import numpy as np\n","np.bool = np.bool_\n","from handyspark import *\n","hsdf = HandyFrame(facts_gdp_spark)\n","hsdf.isnull()"]},{"cell_type":"code","execution_count":39,"id":"f66bd6bc","metadata":{},"outputs":[],"source":["# Add unique ID\n","facts_gdp_spark = facts_gdp_spark.withColumn(\"facts_gdp_id\", monotonically_increasing_id()+1)\n","\n","# Add to tables\n","tables.append([facts_gdp_spark,\"facts_gdp\"])"]},{"cell_type":"markdown","id":"b34378d0","metadata":{},"source":["# Facts PPP Loans"]},{"cell_type":"code","execution_count":41,"id":"da70ed83","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transforming PySpark DataFrame...\n","Completed transforming PySpark DataFrame.\n"]},{"data":{"text/plain":["['sba_guaranty_percentage',\n"," 'initial_approval_amount',\n"," 'current_approval_amount',\n"," 'undisbursed_amount',\n"," 'forgiveness_amount',\n"," 'loan_number',\n"," 'loan_status',\n"," 'term',\n"," 'rural_urban_indicator',\n"," 'hubzone_indicator',\n"," 'lmi_indicator',\n"," 'jobs_reported',\n"," 'sba_office_code',\n"," 'servicing_lender_location_id',\n"," 'originating_lender_location_id',\n"," 'processing_method',\n"," 'date_approved_id',\n"," 'loan_status_date_id',\n"," 'forgiveness_date_id',\n"," 'borrower_id',\n"," 'NAICS_code',\n"," 'fact_ppp_id']"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# Small function to convert date columns to date_id to connect to dim_date table.\n","def date_to_id(df, column_name):\n","    df = df.withColumn(column_name+\"_id\", date_format(column_name, \"yyyyMMdd\").cast(\"int\"))\n","    df = df.drop(column_name)\n","    return df\n","\n","\n","# Create facts\n","facts_PPP_loans = ppp_df.select(\"SBAGuarantyPercentage\",\"InitialApprovalAmount\",\"CurrentApprovalAmount\",\n","                               \"UndisbursedAmount\",\"ForgivenessAmount\",\"LoanNumber\",\"LoanStatus\",\"Term\",\n","                               \"RuralUrbanIndicator\",\"HubzoneIndicator\",\"LMIIndicator\",\"JobsReported\",\n","                                \"date_approved\", \"loan_status_date\",\"forgiveness_date\",\n","                               \"SBAOfficeCode\",\"ServicingLenderLocationID\",\"OriginatingLenderLocationID\",\n","                               \"ProcessingMethod\",\"NAICSCode\")\n","\n","# Convert date cols to date_ids so we can connect it to the dim date if needed\n","facts_PPP_loans = date_to_id(facts_PPP_loans,\"date_approved\")\n","facts_PPP_loans = date_to_id(facts_PPP_loans,\"loan_status_date\")\n","facts_PPP_loans = date_to_id(facts_PPP_loans,\"forgiveness_date\")\n","\n","\n","# Fix names\n","facts_PPP_loans = df_to_snake_case(facts_PPP_loans)\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"s_b_a_office_code\",\"sba_office_code\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"s_b_a_guaranty_percentage\",\"sba_guaranty_percentage\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"servicing_lender_location_i_d\",\"servicing_lender_location_id\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"originating_lender_location_i_d\",\"originating_lender_location_id\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"l_m_i_indicator\",\"lmi_indicator\")\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"n_a_i_c_s_code\",\"NAICS_code\")\n","\n","\n","# Add foreign IDs\n","facts_PPP_loans = facts_PPP_loans.withColumn(\"borrower_id\", col(\"loan_number\")) \n","\n","# Adding the industry_id as a foreign key.\n","#- 1st, join facts dataframe with dim_industry on the naics code\n","facts_PPP_loans = facts_PPP_loans.join(spark.createDataFrame(dim_industry), \n","                                       on=\"NAICS_code\", how=\"inner\")\n","#- 2nd, drop all columns from dim_industry beside the industry id\n","facts_PPP_loans = facts_PPP_loans.drop(\"NAICS_code\",\"industry_type\",\"industry_name\")\n","\n","#- 3rd, rename industry_id to NAICS_code_industry_id\n","facts_PPP_loans = facts_PPP_loans.withColumnRenamed(\"industry_id\",\"NAICS_code\")\n","\n","# Add unique IDs\n","facts_PPP_loans = facts_PPP_loans.withColumn(\"fact_ppp_id\", monotonically_increasing_id()+1)\n","\n","#Remove duplicates\n","facts_PPP_loans = facts_PPP_loans.distinct()\n","\n","# Add to tables\n","tables.append([facts_PPP_loans,\"facts_PPP_loans\"])\n","\n","# Show\n","facts_PPP_loans.columns"]},{"cell_type":"markdown","id":"ca09ff1e","metadata":{},"source":["# Functions for saving\n","\n","Note: All functions assume we have global variable \"bucket\" that contains the name of the bucket we are working with"]},{"cell_type":"code","execution_count":42,"id":"f4ca4ca2","metadata":{},"outputs":[],"source":["def check_folder_exists(folder_name):\n","    \n","    # Grab the bucket\n","    client = storage.Client()\n","    bucket_ = client.get_bucket(bucket)\n","    \n","    # List objects in the bucket with the folder prefix\n","    blobs = bucket_.list_blobs(prefix=folder_name + '/')\n","    \n","    # Check if any blob exists under this folder\n","    for blob in blobs:\n","        if blob.name.startswith(folder_name + '/'):\n","            print(f\"Folder '{folder_name}' exists in bucket '{bucket}'.\")\n","            return True\n","    \n","    print(f\"Folder '{folder_name}' does not exist in bucket '{bucket}'.\")\n","    return False"]},{"cell_type":"code","execution_count":43,"id":"92f23f8d","metadata":{},"outputs":[],"source":["def create_folder(path, name):\n","    \n","    if check_folder_exists(name): \n","        print(path+name+'/'+' already exists. Abandoning folder creation')\n","        return\n","    \n","    # Initialize the GCS client\n","    client = storage.Client()\n","\n","    # Get the bucket\n","    _bucket = client.get_bucket(bucket)\n","\n","    # Define the folder path\n","    folder_path = path+name+'/'\n","\n","    # Create a dummy file in the folder (this will simulate the folder in GCS)\n","    # The 'blob' will not be a real file, but will create the \"folder\"\n","    blob = _bucket.blob(folder_path + 'placeholder.txt')  # You can name it anything, like 'placeholder.txt'\n","\n","    # Upload an empty string or any content to simulate the folder creation\n","    blob.upload_from_string('')\n","\n","    print(f\"Folder '{folder_path}' created successfully in the bucket '{bucket}'\")"]},{"cell_type":"code","execution_count":44,"id":"fa75ff70","metadata":{},"outputs":[],"source":["def delete_files_named(name_of_file_to_delete):\n","    # Initialize a client\n","    client = storage.Client()\n","\n","    # Specify the bucket name\n","    _bucket = client.bucket(bucket)\n","\n","    # List and delete all files named \"placeholder.txt\"\n","    blobs = _bucket.list_blobs()\n","\n","    count_deleted = 0\n","    for blob in blobs:\n","        if blob.name.endswith(name_of_file_to_delete):\n","            blob.delete()\n","            print(f\"Deleted: {blob.name}\")\n","            count_deleted += 1\n","            \n","    \n","    print(f\"Deletion of all '{name_of_file_to_delete}' files is complete. Total deleted: \"+str(count_deleted))"]},{"cell_type":"code","execution_count":45,"id":"1eeb42b6","metadata":{},"outputs":[],"source":["def save_df(df,name,save_as=\"parquet\",gcs_path=None):\n","\n","    #we must define the bucket variable at the start of the script, before calling this function.\n","    \n","    # Define the GCS path for saving the file\n","    if gcs_path == None:\n","        gcs_path = 'gs://'+bucket+'/dim_ready/'+name+'/'+name+'.'+save_as\n","    \n","    \n","    \n","    print(f\"Creating '{name}' folder...\")\n","    create_folder('dim_ready/',name)\n","    delete_files_named(\"placeholder.txt\")\n","    \n","    print(\"Beginning saving process...\")\n","    flag = 0 # this var will let us know is there as been an error\n","    \n","    #Saves Pandas dataframe\n","    if isinstance(df, pd.DataFrame):\n","        # Initialize GCS file system\n","        fs = gcsfs.GCSFileSystem(project='cis4400-group-project')\n","\n","        # Save DataFrame to the \"cleaned\" folder in the GCS bucket\n","        with fs.open(gcs_path, 'w') as f:\n","            if save_as == \"csv\":\n","                df.to_csv(f, index=False)\n","            else:\n","                print(\"INVALD FILE FORMAT. TRY [csv]\")\n","                flag+=1\n","        \n","        if flag == 0:\n","            print(\"Successfully saved \"+name+ \"!\")\n","    \n","    #Saves PySpark dataframe\n","    elif isinstance(df, PySparkDataFrame):\n","        if save_as == \"parquet\":\n","            df.write.parquet(gcs_path,mode=\"overwrite\")\n","        elif save_as == \"csv\":\n","            df.write.csv(gcs_path,mode=\"overwrite\")\n","        elif save_as == \"avro\":\n","            df.write.format(\"avro\").save(gcs_path,mode=\"overwrite\")\n","        else:\n","            print(\"INVALD FILE FORMAT. TRY [csv] or [parquet] or [avro]\")\n","            flag+=1\n","        \n","        if flag == 0:\n","            print(\"Successfully saved \"+name+ \"!\")\n","        \n","    #No valid dataframe found\n","    else:\n","        print(\"ERROR: INVALID DATAFRAME - NO PROCEDURE APPLIED\")"]},{"cell_type":"code","execution_count":46,"id":"ed33de49","metadata":{},"outputs":[],"source":["#this function accepts a list of tables, that each contain 2 elements, the table itself, and the name of the table.\n","#Example, table[0] = [df_1,\"df_1_name\"], table[1][0] = df_2, table[3][1] = \"df_4_name\"\n","def save_list_of_df(list_of_tables,pandas_save=\"csv\",pyspark_save=\"parquet\"):\n","    for table in list_of_tables:\n","        if isinstance(table[0], pd.DataFrame):\n","            save_df(table[0],table[1],save_as=pandas_save)\n","        elif isinstance(table[0], PySparkDataFrame):\n","            save_df(table[0],table[1],save_as=pyspark_save)"]},{"cell_type":"markdown","id":"9873c12d","metadata":{},"source":["# Saving Dims and Facts"]},{"cell_type":"code","execution_count":47,"id":"22534c1e","metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating 'dim_borrower' folder...\n","Folder 'dim_borrower' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_borrower/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_borrower/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved dim_borrower!\n","Creating 'dim_SBA_office' folder...\n","Folder 'dim_SBA_office' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_SBA_office/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_SBA_office/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n","Successfully saved dim_SBA_office!\n","Creating 'dim_processing_method' folder...\n","Folder 'dim_processing_method' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_processing_method/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_processing_method/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n","Successfully saved dim_processing_method!\n","Creating 'dim_originating_lender' folder...\n","Folder 'dim_originating_lender' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_originating_lender/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_originating_lender/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved dim_originating_lender!\n","Creating 'dim_servicing_lender' folder...\n","Folder 'dim_servicing_lender' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_servicing_lender/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_servicing_lender/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved dim_servicing_lender!\n","Creating 'dim_date' folder...\n","Folder 'dim_date' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_date/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_date/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n","Successfully saved dim_date!\n","Creating 'dim_industry' folder...\n","Folder 'dim_industry' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_industry/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_industry/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n","Successfully saved dim_industry!\n","Creating 'dim_census_location' folder...\n","Folder 'dim_census_location' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/dim_census_location/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/dim_census_location/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved dim_census_location!\n","Creating 'facts_gdp' folder...\n","Folder 'facts_gdp' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/facts_gdp/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/facts_gdp/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved facts_gdp!\n","Creating 'facts_PPP_loans' folder...\n","Folder 'facts_PPP_loans' does not exist in bucket 'ppp-loans-bucket'.\n","Folder 'dim_ready/facts_PPP_loans/' created successfully in the bucket 'ppp-loans-bucket'\n","Deleted: dim_ready/facts_PPP_loans/placeholder.txt\n","Deletion of all 'placeholder.txt' files is complete. Total deleted: 1\n","Beginning saving process...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Successfully saved facts_PPP_loans!\n"]}],"source":["#We will simply save all Pandas dataframes as CSV's and all PySpark ones as parquet\n","\n","ENABLE_SAVE = True #boolean to quickly turn on/off saving. Good to turn off saving when debugging.\n","\n","if ENABLE_SAVE:\n","    save_list_of_df(tables)"]},{"cell_type":"code","execution_count":48,"id":"641593a0","metadata":{},"outputs":[],"source":["# DIFFERENCES BETWEEN THIS AND CURRENT DIM MODEL\n","\n","# PPP Fact Table currently has \"term\" and \"term_date_id\" in the model. However...\n","# Script wise, I did not include term_date_id, and left term as is since it doesnt correspond to a date."]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}